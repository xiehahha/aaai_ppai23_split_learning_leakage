{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "rRsykYcP4CxW"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.preprocessing import StandardScaler,Normalizer\n",
        "from sklearn.model_selection import train_test_split\n",
        "torch.manual_seed(42)\n",
        "from itertools import combinations\n",
        "from itertools import accumulate\n",
        "import copy, pickle, math\n",
        "import pandas as pd\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.neural_network import MLPRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import r2_score\n",
        "import pandas as pd"
      ],
      "metadata": {
        "id": "Qmnt_CucWSj4"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cal_housing = fetch_california_housing()\n",
        "X = pd.DataFrame(cal_housing.data,columns=cal_housing.feature_names)\n",
        "y = cal_housing.target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,random_state=1, test_size=0.2)"
      ],
      "metadata": {
        "id": "2MxzzA-HWXCg"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sc_X = StandardScaler()\n",
        "X_trainscaled=sc_X.fit_transform(X_train)\n",
        "X_testscaled=sc_X.transform(X_test)"
      ],
      "metadata": {
        "id": "Vzr6n_76Wanx"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQRaC4ZtaHzH",
        "outputId": "baa241d6-304e-4037-80c3-a648511fc70a"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.556, 1.146, 1.375, ..., 1.048, 1.407, 1.26 ])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "reg = MLPRegressor(hidden_layer_sizes=(64,64,64),activation=\"relu\" ,random_state=1, max_iter=2000).fit(X_trainscaled, y_train)"
      ],
      "metadata": {
        "id": "R4uGNHFfZYCX"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "reg.predict(X_trainscaled[:5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vTbtfn1YZ0M2",
        "outputId": "f879ad7b-880e-4a18-f1a1-92f7795ac2eb"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.50870572, 1.43059859, 1.40194489, 1.99221932, 4.58279794])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OiIsgIokZ_QO",
        "outputId": "8daf4033-e14e-48ee-a047-a9d30d52a47b"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([2.556, 1.146, 1.375, 1.188, 4.227])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# load the dataset CA pricing \n",
        "class CADataset(torch.utils.data.Dataset):\n",
        "\n",
        "  def __init__(self, X, y, scale_data=True):\n",
        "    if not torch.is_tensor(X) and not torch.is_tensor(y):\n",
        "      # Apply scaling if necessary\n",
        "      if scale_data:\n",
        "          X = StandardScaler().fit_transform(X)\n",
        "    \n",
        "      self.X = torch.from_numpy(X)\n",
        "      self.y = torch.from_numpy(y)\n",
        "\n",
        "  def __len__(self):\n",
        "      return len(self.X)\n",
        "\n",
        "  def __getitem__(self, i):\n",
        "      return self.X[i], self.y[i]\n",
        "\n",
        "cal_housing = fetch_california_housing()\n",
        "X = pd.DataFrame(cal_housing.data,columns=cal_housing.feature_names)\n",
        "y = cal_housing.target\n",
        "X = StandardScaler().fit_transform(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,random_state=1, test_size=0.2)\n",
        "\n",
        "dataset_train = CADataset(X_train, y_train)\n",
        "trainloader = torch.utils.data.DataLoader(dataset_train, batch_size=200, shuffle=True, num_workers=1)\n",
        "\n",
        "dataset_test = CADataset(X_test, y_test)\n",
        "testloader = torch.utils.data.DataLoader(dataset_test, batch_size=10, shuffle=True, num_workers=1)\n"
      ],
      "metadata": {
        "id": "V1M9caax_ABd"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# define the model \n",
        "# 1) non-label--user; 2) label--party\n",
        "\n",
        "class user_m(nn.Module): # add customerized user side\n",
        "  def __init__(self, dim_x=32):\n",
        "      super().__init__()\n",
        "      self.layers = nn.Sequential(\n",
        "      nn.Linear(8, 64),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(64, 64),\n",
        "      nn.ReLU(),\n",
        "      nn.Linear(64, dim_x),\n",
        "      nn.ReLU(),\n",
        "    )\n",
        "  def forward(self, x):\n",
        "    return self.layers(x)\n",
        "\n",
        "\n",
        "class label_m(nn.Module): # add for customerized label party\n",
        "  def __init__(self, dim_x=32):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Linear(dim_x, 16),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(16, 1),\n",
        "    )\n",
        "    \n",
        "  def forward(self, x):\n",
        "    return self.layers(x)\n",
        "\n",
        "class MLP_r(nn.Module):\n",
        "  def __init__(self, dim_x=32):\n",
        "    super().__init__()\n",
        "    self.user = user_m(dim_x)\n",
        "    self.label = label_m(dim_x)\n",
        "\n",
        "  def forward(self, x):\n",
        "    self.f_int = self.user(x)\n",
        "    return self.label(self.f_int)\n",
        "\n",
        "def weights_init(m):\n",
        "    if hasattr(m, \"weight\"):\n",
        "        m.weight.data.uniform_(-0.5, 0.5)\n",
        "    if hasattr(m, \"bias\"):\n",
        "        m.bias.data.uniform_(-0.5, 0.5)\n",
        "\n",
        "\n",
        "\n",
        "class new_ml(nn.Module): # add for customerized label party\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Linear(8, 64),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(64, 64),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(64, 1),\n",
        "    )\n",
        "    \n",
        "  def forward(self, x):\n",
        "    return self.layers(x)\n"
      ],
      "metadata": {
        "id": "LeWrYWdT_OtV"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "'''training and evaluation of a model.'''\n",
        "\n",
        "def train_model(mlp, trainloader, iteration):\n",
        "  train_loss_function = nn.MSELoss()\n",
        "  optimizer = torch.optim.Adam(mlp.parameters())\n",
        "\n",
        "  for epoch in range(0, iteration):\n",
        "    current_loss = 0.0\n",
        "    for i, data in enumerate(trainloader, 0):\n",
        "      inputs, targets = data\n",
        "      inputs, targets = inputs.float(), targets.float()\n",
        "      targets = targets.reshape((targets.shape[0], 1))\n",
        "      optimizer.zero_grad()\n",
        "      outputs = mlp(inputs)\n",
        "      loss = train_loss_function(outputs, targets)   \n",
        "      loss.backward()\n",
        "      optimizer.step()\n",
        "    print ('training epoch: {epoch}\\tLoss: {:0.4f}'.format(loss.item(), epoch=epoch+1))\n",
        "  print('final training loss: {:0.4f}'.format(loss.item()))\n",
        "  return mlp\n",
        "\n",
        "\n",
        "def evaluate(model, testloader):\n",
        "  accumulate_loss = 0\n",
        "  train_loss_function = nn.L1Loss()\n",
        "  for i, data in enumerate(testloader, 0):\n",
        "    inputs, targets = data\n",
        "    inputs, targets = inputs.float(), targets.float()\n",
        "    targets = targets.reshape((targets.shape[0], 1))\n",
        "    outputs = model(inputs)\n",
        "  \n",
        "    loss = train_loss_function(outputs, targets)\n",
        "    accumulate_loss+=loss.item()\n",
        "  return accumulate_loss/len(testloader)\n",
        "\n",
        "if False:\n",
        "  mlp_new = MLP_r(dim_x=16, flag=True)\n",
        "  mlp_new = train_model(mlp_new, trainloader)"
      ],
      "metadata": {
        "id": "FuHBqfmXFn4Q"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if True:\n",
        "  \n",
        "  mlp_new = MLP_r()\n",
        "  mlp_new = train_model(mlp_new, trainloader, 50)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SQy5wQSJP49",
        "outputId": "3edceef9-a558-4cba-c715-40955417780a"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "training epoch: 1\tLoss: 0.6792\n",
            "training epoch: 2\tLoss: 0.5951\n",
            "training epoch: 3\tLoss: 0.4185\n",
            "training epoch: 4\tLoss: 0.5632\n",
            "training epoch: 5\tLoss: 0.3613\n",
            "training epoch: 6\tLoss: 0.3211\n",
            "training epoch: 7\tLoss: 0.2284\n",
            "training epoch: 8\tLoss: 0.3100\n",
            "training epoch: 9\tLoss: 0.3411\n",
            "training epoch: 10\tLoss: 0.4236\n",
            "training epoch: 11\tLoss: 0.3226\n",
            "training epoch: 12\tLoss: 0.2663\n",
            "training epoch: 13\tLoss: 0.1433\n",
            "training epoch: 14\tLoss: 0.3735\n",
            "training epoch: 15\tLoss: 0.2288\n",
            "training epoch: 16\tLoss: 0.2021\n",
            "training epoch: 17\tLoss: 0.2685\n",
            "training epoch: 18\tLoss: 0.1419\n",
            "training epoch: 19\tLoss: 0.4444\n",
            "training epoch: 20\tLoss: 0.2399\n",
            "training epoch: 21\tLoss: 0.2376\n",
            "training epoch: 22\tLoss: 0.3521\n",
            "training epoch: 23\tLoss: 0.2229\n",
            "training epoch: 24\tLoss: 0.2399\n",
            "training epoch: 25\tLoss: 0.3438\n",
            "training epoch: 26\tLoss: 0.4552\n",
            "training epoch: 27\tLoss: 0.3111\n",
            "training epoch: 28\tLoss: 0.2900\n",
            "training epoch: 29\tLoss: 0.3895\n",
            "training epoch: 30\tLoss: 0.2259\n",
            "training epoch: 31\tLoss: 0.2409\n",
            "training epoch: 32\tLoss: 0.2885\n",
            "training epoch: 33\tLoss: 0.2907\n",
            "training epoch: 34\tLoss: 0.3185\n",
            "training epoch: 35\tLoss: 0.4692\n",
            "training epoch: 36\tLoss: 0.3149\n",
            "training epoch: 37\tLoss: 0.3196\n",
            "training epoch: 38\tLoss: 0.4703\n",
            "training epoch: 39\tLoss: 0.1816\n",
            "training epoch: 40\tLoss: 0.3608\n",
            "training epoch: 41\tLoss: 0.2531\n",
            "training epoch: 42\tLoss: 0.2246\n",
            "training epoch: 43\tLoss: 0.2451\n",
            "training epoch: 44\tLoss: 0.4094\n",
            "training epoch: 45\tLoss: 0.1896\n",
            "training epoch: 46\tLoss: 0.2210\n",
            "training epoch: 47\tLoss: 0.4224\n",
            "training epoch: 48\tLoss: 0.3020\n",
            "training epoch: 49\tLoss: 0.2323\n",
            "training epoch: 50\tLoss: 0.1597\n",
            "final training loss: 0.1597\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(mlp_new, testloader)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dbv2E9UiYQBb",
        "outputId": "0dabf35d-e782-4b2e-bc82-512b6a81f0d2"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3.260981149592642"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "mlp_new(dataset_train.X[:5].float())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JKRH9fsbYYOr",
        "outputId": "95a84c5e-a83d-4a1f-cb30-0a958bdffb39"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[2.0811],\n",
              "        [1.5123],\n",
              "        [1.2371],\n",
              "        [2.0557],\n",
              "        [4.7536]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_train.y[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sJ3RV7adYfqe",
        "outputId": "fa783b0c-66a7-4c0b-ae86-0cc878772992"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([2.5560, 1.1460, 1.3750, 1.1880, 4.2270], dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def result_summary(original_score, res_dummy):\n",
        "\n",
        "  res = abs(original_score-torch.tensor(res_dummy))/abs(original_score)\n",
        "  print (\"L1-loss mean\", sum(abs(original_score-torch.tensor(res_dummy)))/score.shape[0])\n",
        "  error = sum(res)/score.shape[0]\n",
        "  print (\"mean error rate (L1)\", error)\n",
        "  import pandas as pd\n",
        "\n",
        "  res_list = [t.detach().numpy().tolist() for t in res]\n",
        "  s = pd.Series(res_list)\n",
        "  print (s.describe())\n",
        "  return error"
      ],
      "metadata": {
        "id": "T219itXlPsoc"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# very raw single_data/target and no list things\n",
        "def square_error(pred, target):\n",
        "  return torch.sum((pred-target)**2)\n",
        "loss_function = square_error\n",
        "\n",
        "def mean_error(pred, target): # do not use L1-error\n",
        "  return torch.sum(abs(pred-target))\n",
        "\n",
        "# use a json file to log it\n",
        "dic = {}\n",
        "loss_function = square_error\n",
        "predic_loss_func = square_error\n",
        "\n",
        "cos = torch.nn.CosineSimilarity(dim=0)\n",
        "\n",
        "def simple_short_test(model, datas, labels, \n",
        "                      label_model, # surrogate model setting\n",
        "                      known_datas=None, known_labels=None, # known data points\n",
        "                      iteration=2000, end_threhold=0.001, op='Adam', learning_rate=1,\n",
        "                      semi_flag=True, lamda1=0.05, lamda3=0.01,\n",
        "                      R_predict_flag=True, lamda2=0.05, \n",
        "                      PRINT_INT=False,\n",
        "                      PRINT_flg=False):\n",
        "  \n",
        "  torch.manual_seed(66)\n",
        "\n",
        "  original_dy_dx_list = []\n",
        "  dummy_score_list = []\n",
        "\n",
        "  for (data, score) in zip(datas, labels):\n",
        "    data = data.reshape(1, -1)\n",
        "    score = score.reshape(1, -1)\n",
        "\n",
        "    # compute the loss to be sent g\n",
        "    f_embding = model.user(data.float())\n",
        "    out = model.label(f_embding)\n",
        "    score = score.reshape((1,-1))\n",
        "    y = loss_function(out,  score.reshape((1, -1)))\n",
        "    dy_dx = torch.autograd.grad(y.float(), f_embding) # g\n",
        "    original_dy_dx = list((_.detach().clone() for _ in dy_dx))\n",
        "  \n",
        "\n",
        "    original_dy_dx_list.append(original_dy_dx)\n",
        "\n",
        "    dummy_score = torch.randn(score.size()).requires_grad_(True)\n",
        "    dummy_score_list.append(dummy_score)\n",
        "  \n",
        "\n",
        "\n",
        "  # if there are less data, select all the data, otherwise randomly select few 3 tuples for penalty\n",
        "  trip_list = list(combinations(range(datas.shape[0]), 3))\n",
        "  original_label = list((_.detach().clone() for _ in dummy_score_list))\n",
        "\n",
        "  torch.manual_seed(42)\n",
        "  #label_model = label_surrogate(dim_x=dim_x, flag=bias_flag)\n",
        "  #label_model = label_m(dim_x)\n",
        "  #label_model = copy.deepcopy(start_label_model)\n",
        "  \n",
        "  if PRINT_flg:\n",
        "    print(\"initila surrogate model parameters\", list(label_model.parameters()))\n",
        "  \n",
        "  # step2b: start the reconstruction process\n",
        "\n",
        "  if op==\"Adam\":\n",
        "    optimizer = torch.optim.Adam(list(label_model.parameters())+dummy_score_list, lr=learning_rate)\n",
        "  elif op==\"SGD\":\n",
        "    optimizer = torch.optim.SGD(list(label_model.parameters())+dummy_score_list, lr=0.01, momentum=0.9)\n",
        "  else:\n",
        "    optimizer = torch.optim.LBFGS(list(label_model.parameters())+dummy_score_list, lr=learning_rate)\n",
        "\n",
        "  \n",
        "\n",
        "  for iters in range(iteration):\n",
        "\n",
        "    # print (\"===========current parameters of iterations\", iters, \" ============\")\n",
        "    # for param_group in optimizer.param_groups:\n",
        "    #   print (list(param_group.values())[0]) \n",
        "\n",
        "    # print (\"current gradient of iterations\", iters)\n",
        "    # print (\"model grad\", list(label_model.parameters())[0].grad)\n",
        "    # for i in range(len(dummy_score_list)):\n",
        "    #   print (\"label grad\", dummy_score_list[i].grad)\n",
        "    if PRINT_INT:\n",
        "      print (\"============current gradient of iterations\", iters, \" ============\")\n",
        "      print (\"GT labels\", labels)\n",
        "      print(\"original score\", model(datas.float()).reshape(1, -1))\n",
        "      print (\"dummy labels\", torch.tensor(dummy_score_list))\n",
        "      print(\"surrogate score \", label_model(model.user(datas.float())).reshape(1, -1))\n",
        "\n",
        "    # known_data, label list\n",
        "    known_list = [1, 2]\n",
        "    def closure():\n",
        "      optimizer.zero_grad()\n",
        "      agg_loss = 0\n",
        "\n",
        "      # all the data point loss     \n",
        "      for (data, score, dummy_score, original_dy_dx) in zip(datas, labels, dummy_score_list, original_dy_dx_list): \n",
        "\n",
        "        f_embding = model.user(data.float())\n",
        "        pred = label_model(f_embding) # dummy prediction\n",
        "        dummy_loss = loss_function(pred, dummy_score)\n",
        "        dummy_dy_dx = torch.autograd.grad(dummy_loss, f_embding, create_graph=True)\n",
        "\n",
        "        grad_diff = 0\n",
        "        for gx, gy in zip(dummy_dy_dx, original_dy_dx): \n",
        "            grad_diff += ((gx - gy) ** 2).sum()\n",
        "\n",
        "        # this regularization to make the surrogate model behaves as normal \n",
        "        if R_predict_flag: # print the predict_loss scale\n",
        "          predict_loss = predic_loss_func(pred, dummy_score)\n",
        "          grad_diff += lamda2*predict_loss\n",
        "        agg_loss+=grad_diff\n",
        "\n",
        "\n",
        "      if known_datas!=None:\n",
        "\n",
        "        known_original_dy_dx_list = []\n",
        "    \n",
        "        for (data, score) in zip(known_datas, known_labels):\n",
        "          data = data.reshape(1, -1)\n",
        "          score = score.reshape(1, -1)\n",
        "\n",
        "          # compute the loss to be sent g\n",
        "          f_embding = model.user(data.float())\n",
        "          out = model.label(f_embding)\n",
        "          score = score.reshape((1,-1))\n",
        "          y = loss_function(out,  score.reshape((1, -1)))\n",
        "          dy_dx = torch.autograd.grad(y.float(), f_embding) # g\n",
        "          known_original_dy_dx = list((_.detach().clone() for _ in dy_dx))\n",
        "        \n",
        "\n",
        "          known_original_dy_dx_list.append(known_original_dy_dx)\n",
        "\n",
        "        # this regularization forces the model surrogate to behave like the original model\n",
        "        # adjust the MODEL\n",
        "        # use the gradient loss with GT label\n",
        "\n",
        "        for (data, score, known_original_dy_dx) in zip(known_datas, known_labels, known_original_dy_dx_list): \n",
        "          f_embding = model.user(data.float())\n",
        "          pred = label_model(f_embding) # dummy prediction\n",
        "          dummy_loss = loss_function(pred, score)\n",
        "          dummy_dy_dx = torch.autograd.grad(dummy_loss, f_embding, create_graph=True)\n",
        "          \n",
        "          #label_loss = loss_function(dummy_score, score)\n",
        "          grad_diff = 0\n",
        "          for gx, gy in zip(dummy_dy_dx, known_original_dy_dx): \n",
        "              grad_diff += ((gx - gy) ** 2).sum()\n",
        "          agg_loss+=lamda1 *grad_diff\n",
        "\n",
        "          predict_loss_known = predic_loss_func(pred, score)\n",
        "          agg_loss += lamda3*predict_loss_known\n",
        "\n",
        "\n",
        "      # add semi-supervised data point (the prediction) \n",
        "\n",
        "      agg_loss.backward()\n",
        "      \n",
        "      return grad_diff\n",
        "\n",
        "    optimizer.step(closure)\n",
        "\n",
        "    \n",
        "    # print (iters, \"%.4f\" % closure().item())\n",
        "\n",
        "    if closure().item() < end_threhold:\n",
        "      break\n",
        "\n",
        "    if iters % 50 == 0: \n",
        "        current_loss = closure()\n",
        "        error = result_summary(labels, dummy_score_list)\n",
        "        print(iters, \"%.4f\" % current_loss.item())\n",
        "  \n",
        "  if PRINT_flg:\n",
        "    print (original_dy_dx)\n",
        "\n",
        "    print(\"GT (ground truth) original score\", labels)\n",
        "    print(\"initial dummy score\", original_label)\n",
        "    print(\"end dummy score\", dummy_score_list)\n",
        "\n",
        "    print (\"ground truth label party model\", list(model.label.parameters()))\n",
        "    print(\"end surrogate label_model\", list(label_model.parameters()))\n",
        "\n",
        "    print(\"original prediction score\", model(datas.float()))\n",
        "    print(\"surrogate prediction score \", label_model(model.user(datas.float())))\n",
        "\n",
        "    \n",
        "  return labels, label_model(model.user(data.float())), dummy_score_list, label_model"
      ],
      "metadata": {
        "id": "FCHdEEGxRTLQ"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class label_surrogate(nn.Module): # add for customerized label party\n",
        "  def __init__(self, dim_x=16, flag=False):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Linear(dim_x, 8, bias=flag),\n",
        "        nn.Linear(8, 1, bias=flag),\n",
        "        # nn.Linear(4, 1, bias=flag),\n",
        "    )\n",
        "    \n",
        "  def forward(self, x):\n",
        "    return self.layers(x)\n",
        "\n",
        "surrogate = label_surrogate(dim_x=32, flag=True)\n",
        "\n",
        "# PATH = \"/content/drive/MyDrive/epoch_m/\"+str(4)\n",
        "# mlp_new = MLP_r(dim_x=16, flag=True)\n",
        "# mlp_new.load_state_dict(torch.load(PATH), strict=False)\n",
        "\n",
        "IND = 0\n",
        "Step = 10\n",
        "num = 5\n",
        "data = dataset_train.X[IND:IND+Step]\n",
        "score = dataset_train.y[IND:IND+Step]\n",
        "\n",
        "\n",
        "known_datas = dataset_train.X[IND+Step:IND+num+Step]\n",
        "known_labels = dataset_train.y[IND+Step:IND+Step+num]\n",
        "# bias seems a strong factor no matter what we choose\n",
        "# we may need a regularization conerning the range of score we consider !\n",
        "original_label, surrogate_score, dummy_score, label_model_p = simple_short_test(mlp_new, data, score, surrogate, \n",
        "                                                                                known_datas, known_labels, \n",
        "                                                                                op=\"Adam\", iteration=3500, learning_rate=1, end_threhold=0.00001,\n",
        "                                                                                lamda1=0.1, lamda3=0.1, R_predict_flag=True, lamda2=0.001, PRINT_flg=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3HMx4KDnRas-",
        "outputId": "a93a9160-67ef-4524-cda9-9f2bf0854735"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initila surrogate model parameters [Parameter containing:\n",
            "tensor([[ 0.1352,  0.1467, -0.0414,  0.1624, -0.0387,  0.0357, -0.0861,  0.1038,\n",
            "          0.1558, -0.1297,  0.1537,  0.0331,  0.1306,  0.0239,  0.0852, -0.0250,\n",
            "          0.1363,  0.0261, -0.0825,  0.0451, -0.0814, -0.0207, -0.0718,  0.1173,\n",
            "         -0.1395, -0.0815, -0.0499, -0.1063,  0.0167, -0.1746,  0.1596, -0.1502],\n",
            "        [ 0.1365,  0.0294, -0.0574,  0.1092,  0.0276,  0.1428,  0.0193, -0.0558,\n",
            "          0.0475, -0.0479,  0.0744,  0.1578,  0.1022, -0.0773,  0.1020,  0.0316,\n",
            "          0.0898, -0.1077, -0.1750, -0.0683, -0.1356,  0.1451,  0.0509,  0.0732,\n",
            "          0.0559, -0.0031,  0.1383, -0.1256,  0.0111, -0.1207,  0.0545, -0.0609],\n",
            "        [ 0.0542, -0.0368,  0.1466, -0.1048, -0.1054, -0.1054,  0.1590,  0.0589,\n",
            "          0.1701, -0.1459, -0.1753, -0.1383, -0.1189,  0.0716,  0.0633,  0.1469,\n",
            "         -0.0913, -0.1205,  0.0938, -0.0715,  0.1073, -0.0419,  0.1011, -0.1373,\n",
            "         -0.0892,  0.0539,  0.0374, -0.0451,  0.1054,  0.1202, -0.1282, -0.0944],\n",
            "        [ 0.1619, -0.0597, -0.0627, -0.1710, -0.1012,  0.0442, -0.0233, -0.1283,\n",
            "          0.0041, -0.1208, -0.1500, -0.0973, -0.1547, -0.1126,  0.1767,  0.0334,\n",
            "          0.0545, -0.1649, -0.1161, -0.0588,  0.0276, -0.1555, -0.0762, -0.1058,\n",
            "          0.0005, -0.0658, -0.0122, -0.1198, -0.1213, -0.1031, -0.0605, -0.1395],\n",
            "        [ 0.1482, -0.0351,  0.1521,  0.0551, -0.1497,  0.1223, -0.0486, -0.0678,\n",
            "         -0.1467, -0.1757,  0.0506, -0.0386,  0.0688, -0.1451,  0.1312, -0.1298,\n",
            "         -0.0305,  0.0369,  0.0913,  0.1427,  0.1610, -0.1402,  0.0445, -0.0760,\n",
            "         -0.0194, -0.1323,  0.1610, -0.1297,  0.0945,  0.0621,  0.0574, -0.0956],\n",
            "        [ 0.1607,  0.0388,  0.0227, -0.1558,  0.0742, -0.0265, -0.0810,  0.1518,\n",
            "          0.0394, -0.0978, -0.0895, -0.0084,  0.0987, -0.0452, -0.1009, -0.0605,\n",
            "         -0.1321,  0.0630,  0.1368, -0.1664,  0.0411,  0.0913,  0.0321, -0.0630,\n",
            "          0.0923,  0.0929,  0.0661, -0.0311, -0.0468,  0.0189, -0.0312, -0.0527],\n",
            "        [ 0.1130,  0.1519, -0.0175, -0.0396,  0.0026, -0.0106,  0.0425,  0.0495,\n",
            "         -0.1606, -0.0652,  0.1489,  0.0689, -0.0088, -0.1066, -0.1082, -0.1584,\n",
            "         -0.0576,  0.0597,  0.1127,  0.0816, -0.1563, -0.1063, -0.0279,  0.1710,\n",
            "          0.0256, -0.0458,  0.0731, -0.0673, -0.1144,  0.1290, -0.0804, -0.0354],\n",
            "        [-0.1759,  0.1183,  0.1339,  0.0644, -0.1233, -0.1745, -0.1436,  0.1318,\n",
            "          0.0849,  0.1488,  0.0926,  0.0447, -0.0017, -0.1344, -0.1515, -0.1653,\n",
            "          0.0724, -0.0868, -0.0356, -0.1017, -0.0322, -0.1244, -0.1155,  0.0586,\n",
            "         -0.0525,  0.1091, -0.0567, -0.1297, -0.0312, -0.0857, -0.0541, -0.1683]],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([ 0.0989, -0.1231,  0.0889,  0.0802,  0.1263, -0.1356,  0.1271, -0.0836],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([[ 0.1312,  0.3320, -0.0499, -0.0027, -0.0814, -0.2952,  0.1697, -0.3510]],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([0.2195], requires_grad=True)]\n",
            "L1-loss mean tensor(0.9769, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.5382, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.538197\n",
            "std       0.481579\n",
            "min       0.023677\n",
            "25%       0.246992\n",
            "50%       0.413757\n",
            "75%       0.720798\n",
            "max       1.677442\n",
            "dtype: float64\n",
            "0 976034.8125\n",
            "L1-loss mean tensor(3.3340, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(2.0285, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      2.028455\n",
            "std       0.828854\n",
            "min       0.888089\n",
            "25%       1.561160\n",
            "50%       1.864395\n",
            "75%       2.303404\n",
            "max       3.518176\n",
            "dtype: float64\n",
            "50 21.8684\n",
            "L1-loss mean tensor(3.2228, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.9433, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.943315\n",
            "std       0.825986\n",
            "min       0.741033\n",
            "25%       1.531429\n",
            "50%       1.839106\n",
            "75%       2.233458\n",
            "max       3.385717\n",
            "dtype: float64\n",
            "100 3.2570\n",
            "L1-loss mean tensor(3.2082, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.9316, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.931593\n",
            "std       0.824113\n",
            "min       0.722276\n",
            "25%       1.528774\n",
            "50%       1.835531\n",
            "75%       2.227551\n",
            "max       3.372729\n",
            "dtype: float64\n",
            "150 1.7566\n",
            "L1-loss mean tensor(3.2012, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.9261, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.926079\n",
            "std       0.823386\n",
            "min       0.713778\n",
            "25%       1.527183\n",
            "50%       1.833475\n",
            "75%       2.225173\n",
            "max       3.367285\n",
            "dtype: float64\n",
            "200 1.5827\n",
            "L1-loss mean tensor(3.1964, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.9223, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.922350\n",
            "std       0.823091\n",
            "min       0.707770\n",
            "25%       1.526160\n",
            "50%       1.831963\n",
            "75%       2.224093\n",
            "max       3.364222\n",
            "dtype: float64\n",
            "250 1.3197\n",
            "L1-loss mean tensor(3.1931, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.9198, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.919843\n",
            "std       0.823055\n",
            "min       0.703555\n",
            "25%       1.525461\n",
            "50%       1.830802\n",
            "75%       2.223880\n",
            "max       3.362765\n",
            "dtype: float64\n",
            "300 1.1317\n",
            "L1-loss mean tensor(3.1909, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.9182, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.918186\n",
            "std       0.823195\n",
            "min       0.700589\n",
            "25%       1.524984\n",
            "50%       1.829879\n",
            "75%       2.224295\n",
            "max       3.362449\n",
            "dtype: float64\n",
            "350 1.0096\n",
            "L1-loss mean tensor(3.1893, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.9171, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.917095\n",
            "std       0.823455\n",
            "min       0.698444\n",
            "25%       1.524658\n",
            "50%       1.829107\n",
            "75%       2.225158\n",
            "max       3.362931\n",
            "dtype: float64\n",
            "400 0.9328\n",
            "L1-loss mean tensor(3.1883, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.9164, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.916368\n",
            "std       0.823801\n",
            "min       0.696816\n",
            "25%       1.524432\n",
            "50%       1.828425\n",
            "75%       2.226341\n",
            "max       3.363960\n",
            "dtype: float64\n",
            "450 0.8844\n",
            "L1-loss mean tensor(3.1875, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.9159, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.915870\n",
            "std       0.824209\n",
            "min       0.695503\n",
            "25%       1.524268\n",
            "50%       1.827791\n",
            "75%       2.227755\n",
            "max       3.365368\n",
            "dtype: float64\n",
            "500 0.8534\n",
            "L1-loss mean tensor(3.1868, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.9155, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.915512\n",
            "std       0.824664\n",
            "min       0.694373\n",
            "25%       1.524142\n",
            "50%       1.827176\n",
            "75%       2.229343\n",
            "max       3.367047\n",
            "dtype: float64\n",
            "550 0.8328\n",
            "L1-loss mean tensor(3.1863, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.9152, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.915236\n",
            "std       0.825159\n",
            "min       0.693341\n",
            "25%       1.524035\n",
            "50%       1.826562\n",
            "75%       2.231068\n",
            "max       3.368926\n",
            "dtype: float64\n",
            "600 0.8185\n",
            "L1-loss mean tensor(3.1858, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.9150, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.915007\n",
            "std       0.825688\n",
            "min       0.692354\n",
            "25%       1.523937\n",
            "50%       1.825937\n",
            "75%       2.232909\n",
            "max       3.370963\n",
            "dtype: float64\n",
            "650 0.8081\n",
            "L1-loss mean tensor(3.1854, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.9148, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.914802\n",
            "std       0.826247\n",
            "min       0.691380\n",
            "25%       1.523839\n",
            "50%       1.825291\n",
            "75%       2.234854\n",
            "max       3.373132\n",
            "dtype: float64\n",
            "700 0.8000\n",
            "L1-loss mean tensor(3.1849, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.9146, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.914606\n",
            "std       0.826837\n",
            "min       0.690396\n",
            "25%       1.523737\n",
            "50%       1.824620\n",
            "75%       2.236895\n",
            "max       3.375419\n",
            "dtype: float64\n",
            "750 0.7934\n",
            "L1-loss mean tensor(3.1844, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.9144, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.914412\n",
            "std       0.827457\n",
            "min       0.689390\n",
            "25%       1.523627\n",
            "50%       1.823920\n",
            "75%       2.239030\n",
            "max       3.377818\n",
            "dtype: float64\n",
            "800 0.7876\n",
            "L1-loss mean tensor(3.1840, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.9142, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.914214\n",
            "std       0.828105\n",
            "min       0.688355\n",
            "25%       1.523509\n",
            "50%       1.823190\n",
            "75%       2.241256\n",
            "max       3.380322\n",
            "dtype: float64\n",
            "850 0.7824\n",
            "L1-loss mean tensor(3.1835, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.9140, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.914010\n",
            "std       0.828784\n",
            "min       0.687287\n",
            "25%       1.523379\n",
            "50%       1.822427\n",
            "75%       2.243574\n",
            "max       3.382932\n",
            "dtype: float64\n",
            "900 0.7776\n",
            "L1-loss mean tensor(3.1829, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.9138, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.913797\n",
            "std       0.829494\n",
            "min       0.686185\n",
            "25%       1.523238\n",
            "50%       1.821629\n",
            "75%       2.245984\n",
            "max       3.385647\n",
            "dtype: float64\n",
            "950 0.7729\n",
            "L1-loss mean tensor(3.1824, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.9136, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.913576\n",
            "std       0.830234\n",
            "min       0.685046\n",
            "25%       1.523085\n",
            "50%       1.820798\n",
            "75%       2.248487\n",
            "max       3.388467\n",
            "dtype: float64\n",
            "1000 0.7683\n",
            "L1-loss mean tensor(3.1818, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.9133, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.913346\n",
            "std       0.831007\n",
            "min       0.683872\n",
            "25%       1.522919\n",
            "50%       1.819930\n",
            "75%       2.251085\n",
            "max       3.391395\n",
            "dtype: float64\n",
            "1050 0.7638\n",
            "L1-loss mean tensor(3.1812, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.9131, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.913107\n",
            "std       0.831811\n",
            "min       0.682662\n",
            "25%       1.522739\n",
            "50%       1.819027\n",
            "75%       2.253777\n",
            "max       3.394432\n",
            "dtype: float64\n",
            "1100 0.7593\n",
            "L1-loss mean tensor(3.1806, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.9129, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.912859\n",
            "std       0.832649\n",
            "min       0.681416\n",
            "25%       1.522546\n",
            "50%       1.818087\n",
            "75%       2.256565\n",
            "max       3.397579\n",
            "dtype: float64\n",
            "1150 0.7547\n",
            "L1-loss mean tensor(3.1799, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.9126, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.912601\n",
            "std       0.833521\n",
            "min       0.680137\n",
            "25%       1.522337\n",
            "50%       1.817109\n",
            "75%       2.259451\n",
            "max       3.400837\n",
            "dtype: float64\n",
            "1200 0.7500\n",
            "L1-loss mean tensor(3.1792, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.9123, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.912335\n",
            "std       0.834428\n",
            "min       0.678823\n",
            "25%       1.522113\n",
            "50%       1.816093\n",
            "75%       2.262434\n",
            "max       3.404207\n",
            "dtype: float64\n",
            "1250 0.7452\n",
            "L1-loss mean tensor(3.1785, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.9121, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.912060\n",
            "std       0.835371\n",
            "min       0.677476\n",
            "25%       1.521873\n",
            "50%       1.815039\n",
            "75%       2.265517\n",
            "max       3.407692\n",
            "dtype: float64\n",
            "1300 0.7403\n",
            "L1-loss mean tensor(3.1778, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.9118, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.911775\n",
            "std       0.836349\n",
            "min       0.676097\n",
            "25%       1.521616\n",
            "50%       1.813944\n",
            "75%       2.268699\n",
            "max       3.411292\n",
            "dtype: float64\n",
            "1350 0.7352\n",
            "L1-loss mean tensor(3.1771, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.9115, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.911482\n",
            "std       0.837365\n",
            "min       0.674687\n",
            "25%       1.521340\n",
            "50%       1.812809\n",
            "75%       2.271983\n",
            "max       3.415009\n",
            "dtype: float64\n",
            "1400 0.7301\n",
            "L1-loss mean tensor(3.1763, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.9112, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.911179\n",
            "std       0.838419\n",
            "min       0.673246\n",
            "25%       1.521045\n",
            "50%       1.811633\n",
            "75%       2.275368\n",
            "max       3.418844\n",
            "dtype: float64\n",
            "1450 0.7248\n",
            "L1-loss mean tensor(3.1755, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.9109, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.910868\n",
            "std       0.839511\n",
            "min       0.671775\n",
            "25%       1.520730\n",
            "50%       1.810415\n",
            "75%       2.278857\n",
            "max       3.422799\n",
            "dtype: float64\n",
            "1500 0.7194\n",
            "L1-loss mean tensor(3.1746, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.9105, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.910547\n",
            "std       0.840643\n",
            "min       0.670275\n",
            "25%       1.520393\n",
            "50%       1.809154\n",
            "75%       2.282450\n",
            "max       3.426875\n",
            "dtype: float64\n",
            "1550 0.7138\n",
            "L1-loss mean tensor(3.1738, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.9102, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.910217\n",
            "std       0.841816\n",
            "min       0.668747\n",
            "25%       1.520034\n",
            "50%       1.807848\n",
            "75%       2.286147\n",
            "max       3.431072\n",
            "dtype: float64\n",
            "1600 0.7082\n",
            "L1-loss mean tensor(3.1729, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.9099, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.909878\n",
            "std       0.843030\n",
            "min       0.667192\n",
            "25%       1.519652\n",
            "50%       1.806498\n",
            "75%       2.289951\n",
            "max       3.435395\n",
            "dtype: float64\n",
            "1650 0.7024\n",
            "L1-loss mean tensor(3.1720, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.9095, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.909529\n",
            "std       0.844287\n",
            "min       0.665611\n",
            "25%       1.519245\n",
            "50%       1.805102\n",
            "75%       2.293861\n",
            "max       3.439842\n",
            "dtype: float64\n",
            "1700 0.6965\n",
            "L1-loss mean tensor(3.1710, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.9092, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.909172\n",
            "std       0.845587\n",
            "min       0.664006\n",
            "25%       1.518812\n",
            "50%       1.803658\n",
            "75%       2.297880\n",
            "max       3.444417\n",
            "dtype: float64\n",
            "1750 0.6904\n",
            "L1-loss mean tensor(3.1700, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.9088, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.908805\n",
            "std       0.846932\n",
            "min       0.662376\n",
            "25%       1.518351\n",
            "50%       1.802167\n",
            "75%       2.302008\n",
            "max       3.449119\n",
            "dtype: float64\n",
            "1800 0.6843\n",
            "L1-loss mean tensor(3.1690, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.9084, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.908428\n",
            "std       0.848322\n",
            "min       0.660725\n",
            "25%       1.517862\n",
            "50%       1.800627\n",
            "75%       2.306246\n",
            "max       3.453952\n",
            "dtype: float64\n",
            "1850 0.6780\n",
            "L1-loss mean tensor(3.1679, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.9080, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.908043\n",
            "std       0.849759\n",
            "min       0.659052\n",
            "25%       1.517343\n",
            "50%       1.799036\n",
            "75%       2.310595\n",
            "max       3.458916\n",
            "dtype: float64\n",
            "1900 0.6716\n",
            "L1-loss mean tensor(3.1669, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.9076, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.907648\n",
            "std       0.851243\n",
            "min       0.657360\n",
            "25%       1.516792\n",
            "50%       1.797394\n",
            "75%       2.315057\n",
            "max       3.464013\n",
            "dtype: float64\n",
            "1950 0.6651\n",
            "L1-loss mean tensor(3.1657, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.9072, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.907243\n",
            "std       0.852776\n",
            "min       0.655650\n",
            "25%       1.516208\n",
            "50%       1.795700\n",
            "75%       2.319632\n",
            "max       3.469245\n",
            "dtype: float64\n",
            "2000 0.6584\n",
            "L1-loss mean tensor(3.1646, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.9068, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.906830\n",
            "std       0.854358\n",
            "min       0.653923\n",
            "25%       1.515589\n",
            "50%       1.793952\n",
            "75%       2.324321\n",
            "max       3.474613\n",
            "dtype: float64\n",
            "2050 0.6517\n",
            "L1-loss mean tensor(3.1634, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.9064, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.906407\n",
            "std       0.855992\n",
            "min       0.652182\n",
            "25%       1.514935\n",
            "50%       1.792149\n",
            "75%       2.329126\n",
            "max       3.480119\n",
            "dtype: float64\n",
            "2100 0.6449\n",
            "L1-loss mean tensor(3.1622, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.9060, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.905975\n",
            "std       0.857677\n",
            "min       0.650428\n",
            "25%       1.514242\n",
            "50%       1.790291\n",
            "75%       2.334047\n",
            "max       3.485765\n",
            "dtype: float64\n",
            "2150 0.6379\n",
            "L1-loss mean tensor(3.1609, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.9055, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.905534\n",
            "std       0.859415\n",
            "min       0.648662\n",
            "25%       1.513511\n",
            "50%       1.788375\n",
            "75%       2.339086\n",
            "max       3.491553\n",
            "dtype: float64\n",
            "2200 0.6309\n",
            "L1-loss mean tensor(3.1596, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.9051, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.905083\n",
            "std       0.861208\n",
            "min       0.646887\n",
            "25%       1.512737\n",
            "50%       1.786400\n",
            "75%       2.344244\n",
            "max       3.497483\n",
            "dtype: float64\n",
            "2250 0.6238\n",
            "L1-loss mean tensor(3.1583, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.9046, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.904624\n",
            "std       0.863056\n",
            "min       0.645104\n",
            "25%       1.511921\n",
            "50%       1.784365\n",
            "75%       2.349521\n",
            "max       3.503557\n",
            "dtype: float64\n",
            "2300 0.6166\n",
            "L1-loss mean tensor(3.1569, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.9042, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.904155\n",
            "std       0.864961\n",
            "min       0.643318\n",
            "25%       1.511060\n",
            "50%       1.782269\n",
            "75%       2.354918\n",
            "max       3.509778\n",
            "dtype: float64\n",
            "2350 0.6093\n",
            "L1-loss mean tensor(3.1555, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.9037, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.903678\n",
            "std       0.866923\n",
            "min       0.641525\n",
            "25%       1.510152\n",
            "50%       1.780111\n",
            "75%       2.360437\n",
            "max       3.516147\n",
            "dtype: float64\n",
            "2400 0.6019\n",
            "L1-loss mean tensor(3.1541, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.9032, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.903192\n",
            "std       0.868945\n",
            "min       0.639731\n",
            "25%       1.509195\n",
            "50%       1.777889\n",
            "75%       2.366078\n",
            "max       3.522665\n",
            "dtype: float64\n",
            "2450 0.5945\n",
            "L1-loss mean tensor(3.1526, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.9027, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.902697\n",
            "std       0.871027\n",
            "min       0.637941\n",
            "25%       1.508187\n",
            "50%       1.775601\n",
            "75%       2.371842\n",
            "max       3.529334\n",
            "dtype: float64\n",
            "2500 0.5869\n",
            "L1-loss mean tensor(3.1511, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.9022, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.902193\n",
            "std       0.873170\n",
            "min       0.636155\n",
            "25%       1.507127\n",
            "50%       1.773246\n",
            "75%       2.377731\n",
            "max       3.536156\n",
            "dtype: float64\n",
            "2550 0.5794\n",
            "L1-loss mean tensor(3.1495, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.9017, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.901681\n",
            "std       0.875376\n",
            "min       0.634376\n",
            "25%       1.506011\n",
            "50%       1.770824\n",
            "75%       2.383744\n",
            "max       3.543132\n",
            "dtype: float64\n",
            "2600 0.5717\n",
            "L1-loss mean tensor(3.1479, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.9012, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.901160\n",
            "std       0.877646\n",
            "min       0.632605\n",
            "25%       1.504839\n",
            "50%       1.768332\n",
            "75%       2.389883\n",
            "max       3.550263\n",
            "dtype: float64\n",
            "2650 0.5640\n",
            "L1-loss mean tensor(3.1463, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.9006, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.900632\n",
            "std       0.879981\n",
            "min       0.630847\n",
            "25%       1.503607\n",
            "50%       1.765768\n",
            "75%       2.396149\n",
            "max       3.557553\n",
            "dtype: float64\n",
            "2700 0.5563\n",
            "L1-loss mean tensor(3.1446, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.9001, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.900095\n",
            "std       0.882382\n",
            "min       0.629104\n",
            "25%       1.502314\n",
            "50%       1.763132\n",
            "75%       2.402543\n",
            "max       3.565000\n",
            "dtype: float64\n",
            "2750 0.5485\n",
            "L1-loss mean tensor(3.1428, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.8996, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.899550\n",
            "std       0.884851\n",
            "min       0.627378\n",
            "25%       1.499224\n",
            "50%       1.760422\n",
            "75%       2.409064\n",
            "max       3.572609\n",
            "dtype: float64\n",
            "2800 0.5407\n",
            "L1-loss mean tensor(3.1410, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.8990, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.898998\n",
            "std       0.887390\n",
            "min       0.625672\n",
            "25%       1.494225\n",
            "50%       1.757636\n",
            "75%       2.415714\n",
            "max       3.580379\n",
            "dtype: float64\n",
            "2850 0.5329\n",
            "L1-loss mean tensor(3.1392, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.8984, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.898438\n",
            "std       0.889998\n",
            "min       0.623991\n",
            "25%       1.489080\n",
            "50%       1.754773\n",
            "75%       2.422493\n",
            "max       3.588312\n",
            "dtype: float64\n",
            "2900 0.5250\n",
            "L1-loss mean tensor(3.1373, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.8979, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.897870\n",
            "std       0.892679\n",
            "min       0.622337\n",
            "25%       1.483786\n",
            "50%       1.751831\n",
            "75%       2.429403\n",
            "max       3.596412\n",
            "dtype: float64\n",
            "2950 0.5171\n",
            "L1-loss mean tensor(3.1354, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.8973, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.897296\n",
            "std       0.895431\n",
            "min       0.620713\n",
            "25%       1.478339\n",
            "50%       1.748809\n",
            "75%       2.436443\n",
            "max       3.604675\n",
            "dtype: float64\n",
            "3000 0.5092\n",
            "L1-loss mean tensor(3.1334, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.8967, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.896714\n",
            "std       0.898259\n",
            "min       0.619123\n",
            "25%       1.472736\n",
            "50%       1.745705\n",
            "75%       2.443614\n",
            "max       3.613108\n",
            "dtype: float64\n",
            "3050 0.5013\n",
            "L1-loss mean tensor(3.1314, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.8961, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.896126\n",
            "std       0.901161\n",
            "min       0.617570\n",
            "25%       1.466975\n",
            "50%       1.742516\n",
            "75%       2.450917\n",
            "max       3.621709\n",
            "dtype: float64\n",
            "3100 0.4934\n",
            "L1-loss mean tensor(3.1293, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.8955, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.895531\n",
            "std       0.904141\n",
            "min       0.616059\n",
            "25%       1.461050\n",
            "50%       1.739243\n",
            "75%       2.458352\n",
            "max       3.630481\n",
            "dtype: float64\n",
            "3150 0.4855\n",
            "L1-loss mean tensor(3.1272, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.8949, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.894930\n",
            "std       0.907199\n",
            "min       0.614591\n",
            "25%       1.454960\n",
            "50%       1.735882\n",
            "75%       2.465920\n",
            "max       3.639425\n",
            "dtype: float64\n",
            "3200 0.4776\n",
            "L1-loss mean tensor(3.1250, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.8943, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.894323\n",
            "std       0.910336\n",
            "min       0.613171\n",
            "25%       1.448700\n",
            "50%       1.732433\n",
            "75%       2.473621\n",
            "max       3.648542\n",
            "dtype: float64\n",
            "3250 0.4697\n",
            "L1-loss mean tensor(3.1228, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.8937, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.893710\n",
            "std       0.913554\n",
            "min       0.611803\n",
            "25%       1.442267\n",
            "50%       1.728893\n",
            "75%       2.481455\n",
            "max       3.657832\n",
            "dtype: float64\n",
            "3300 0.4619\n",
            "L1-loss mean tensor(3.1205, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.8931, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.893091\n",
            "std       0.916854\n",
            "min       0.610491\n",
            "25%       1.435658\n",
            "50%       1.725261\n",
            "75%       2.489423\n",
            "max       3.667298\n",
            "dtype: float64\n",
            "3350 0.4541\n",
            "L1-loss mean tensor(3.1182, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.8925, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.892467\n",
            "std       0.920238\n",
            "min       0.609239\n",
            "25%       1.428869\n",
            "50%       1.721534\n",
            "75%       2.497525\n",
            "max       3.676941\n",
            "dtype: float64\n",
            "3400 0.4463\n",
            "L1-loss mean tensor(3.1158, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(1.8918, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      1.891838\n",
            "std       0.923707\n",
            "min       0.608050\n",
            "25%       1.421896\n",
            "50%       1.717712\n",
            "75%       2.505761\n",
            "max       3.686762\n",
            "dtype: float64\n",
            "3450 0.4385\n",
            "[tensor([[ 0.0342, -0.2414,  0.0482,  0.1032,  0.2289, -0.2431,  0.0122, -0.0316,\n",
            "         -0.1404,  0.1633,  0.0117, -0.1587, -0.0837, -0.1544, -0.1394, -0.1385,\n",
            "         -0.1789, -0.1291,  0.4735,  0.0293, -0.2929,  0.0140, -0.2080,  0.2661,\n",
            "         -0.1799, -0.0429, -0.2073,  0.0513, -0.0647,  0.0746, -0.1398,  0.0153]])]\n",
            "GT (ground truth) original score tensor([2.5560, 1.1460, 1.3750, 1.1880, 4.2270, 0.7500, 1.2950, 1.1700, 1.4540,\n",
            "        2.2590], dtype=torch.float64)\n",
            "initial dummy score [tensor([[1.8289]]), tensor([[-0.2198]]), tensor([[0.3424]]), tensor([[-1.8048]]), tensor([[0.1166]]), tensor([[1.1357]]), tensor([[0.0063]]), tensor([[0.0756]]), tensor([[-0.1351]]), tensor([[0.3050]])]\n",
            "end dummy score [tensor([[-1.6815]], requires_grad=True), tensor([[-1.4851]], requires_grad=True), tensor([[2.2096]], requires_grad=True), tensor([[-3.2035]], requires_grad=True), tensor([[-3.2543]], requires_grad=True), tensor([[2.7070]], requires_grad=True), tensor([[-2.0547]], requires_grad=True), tensor([[2.1064]], requires_grad=True), tensor([[-0.7319]], requires_grad=True), tensor([[-0.8706]], requires_grad=True)]\n",
            "ground truth label party model [Parameter containing:\n",
            "tensor([[ 1.4490e-01, -1.2645e-02, -4.2654e-02,  6.5490e-02, -2.3292e-01,\n",
            "          2.8864e-01, -4.4506e-02, -5.5372e-02,  1.7648e-01, -2.2459e-01,\n",
            "         -9.1415e-02,  3.6841e-02,  1.2092e-01,  2.2486e-01,  2.5933e-01,\n",
            "          2.1648e-01, -2.9741e-02,  1.2598e-01, -3.2773e-01,  1.4519e-01,\n",
            "          3.1661e-01, -1.3819e-01,  2.4104e-01, -2.5543e-01,  2.0481e-01,\n",
            "          5.6806e-02,  1.6494e-01,  1.5282e-01, -2.8651e-02, -1.3890e-01,\n",
            "          2.4137e-01,  1.7222e-01],\n",
            "        [-2.1078e-02,  2.6043e-01,  5.5690e-02, -5.8179e-02, -1.3620e-01,\n",
            "          9.4879e-02,  1.8922e-01, -1.0636e-01,  2.0715e-02,  6.6318e-02,\n",
            "         -7.2560e-02,  2.5695e-01,  1.5646e-01,  1.6411e-01,  1.3905e-01,\n",
            "          8.1617e-02,  2.0098e-01,  1.6414e-01, -4.0388e-01, -1.1501e-01,\n",
            "          6.0378e-02,  1.1435e-02,  1.9090e-01, -1.3519e-01,  1.6939e-01,\n",
            "          1.1343e-01,  2.0526e-01, -2.1894e-02,  1.3456e-01, -1.4594e-01,\n",
            "          2.0882e-01, -1.2182e-01],\n",
            "        [ 3.5005e-02, -1.0684e-01, -1.4657e-01, -1.0790e-01, -9.3969e-02,\n",
            "         -1.1047e-01,  9.7591e-02, -4.3673e-02, -1.5705e-01, -2.1240e-02,\n",
            "         -7.1478e-02, -6.7361e-02,  8.5523e-02, -2.3141e-01, -1.9096e-01,\n",
            "          1.5304e-01,  3.2869e-02, -2.5310e-01,  5.5538e-02,  2.5795e-01,\n",
            "         -4.4402e-03, -1.1407e-01,  1.0371e-01,  9.9850e-02, -4.5012e-02,\n",
            "         -6.6638e-02, -3.9001e-02, -5.4608e-02, -1.7509e-01,  1.1034e-01,\n",
            "          4.8631e-02,  7.0972e-02],\n",
            "        [-1.5415e-01,  1.0806e-01,  1.0864e-01,  1.3456e-01, -3.6364e-02,\n",
            "         -6.5071e-02, -1.9972e-01,  1.1411e-01, -5.1102e-02, -1.8961e-01,\n",
            "          1.5411e-01, -6.4741e-02,  6.6148e-02, -6.7711e-02, -6.8826e-02,\n",
            "          1.2935e-01,  1.3061e-01, -1.2476e-01, -1.4634e-02,  9.1931e-02,\n",
            "         -1.5354e-02, -3.7857e-02,  1.1787e-01,  1.3388e-01, -8.4954e-02,\n",
            "          1.1869e-01, -5.9227e-02, -1.7996e-02,  1.0089e-01, -2.6224e-02,\n",
            "         -5.9313e-02, -5.5432e-02],\n",
            "        [-1.6001e-01,  2.3050e-01, -1.1758e-01, -2.0183e-01, -1.6860e-02,\n",
            "          1.6392e-01,  3.8301e-02,  7.9808e-03,  2.7267e-01, -3.1407e-01,\n",
            "         -9.2868e-02,  1.1716e-01, -7.8751e-02, -6.1884e-02,  2.3892e-01,\n",
            "          1.5841e-01,  6.4024e-02,  1.6198e-01, -2.7915e-01, -2.3913e-02,\n",
            "          3.3125e-01, -4.7183e-05,  2.7741e-01, -1.6508e-01,  6.8016e-02,\n",
            "          1.7858e-02,  1.9984e-01, -4.3432e-02,  2.2551e-01, -1.3415e-01,\n",
            "          1.5576e-02,  1.5089e-01],\n",
            "        [-1.5483e-01, -1.9725e-01, -5.2958e-02, -5.6932e-02,  3.9033e-01,\n",
            "         -1.5268e-01,  5.3372e-02,  9.4953e-02, -1.1209e-02,  4.9954e-02,\n",
            "         -1.3610e-01,  1.1817e-01,  8.0645e-02,  1.1117e-01, -2.1640e-01,\n",
            "         -1.8029e-01,  2.8233e-01,  1.0887e-01,  2.5881e-01,  2.2214e-01,\n",
            "         -5.3019e-01, -1.6505e-01, -6.0387e-02,  4.1623e-02, -1.0365e-01,\n",
            "          1.7221e-02, -3.7659e-02, -1.2763e-01, -1.4474e-01, -5.6016e-02,\n",
            "          7.8939e-02, -5.1579e-02],\n",
            "        [ 2.5997e-02,  2.4612e-01, -2.2728e-02, -1.5350e-01, -2.0301e-01,\n",
            "          2.1087e-01, -1.3014e-01,  1.5156e-01,  2.3905e-01, -8.0070e-02,\n",
            "          1.7828e-01,  1.6654e-01,  1.9108e-01,  2.3552e-01, -2.8367e-02,\n",
            "          1.0363e-01,  1.8660e-01,  5.7538e-02, -4.5370e-01, -1.2079e-01,\n",
            "          2.1003e-01, -2.9122e-02,  3.3885e-03, -2.5773e-01,  2.3478e-01,\n",
            "         -1.3654e-01,  1.6838e-01, -1.7152e-01, -2.0102e-02,  1.8322e-02,\n",
            "          2.4149e-01, -1.4879e-01],\n",
            "        [ 6.8105e-02,  1.3224e-02, -1.5758e-01, -1.3939e-01,  7.4793e-02,\n",
            "         -1.0820e-01,  6.9700e-02, -1.3389e-01,  1.1597e-01, -1.2409e-01,\n",
            "          6.1822e-02,  2.0704e-02, -1.5650e-01, -1.1669e-01, -5.8932e-02,\n",
            "         -1.5742e-02,  1.8636e-02, -9.5026e-02,  1.0126e-02, -1.1264e-01,\n",
            "         -1.0099e-01,  1.0936e-01, -6.4018e-02, -1.7169e-01, -5.0749e-03,\n",
            "         -3.5382e-02,  3.3330e-02, -1.0526e-01, -8.6831e-03, -9.6925e-02,\n",
            "         -1.3804e-01,  2.8009e-02],\n",
            "        [ 4.2436e-02,  3.4933e-02,  1.4450e-01, -1.5409e-03, -9.8225e-02,\n",
            "         -4.0670e-01, -2.0575e-01,  5.3786e-02,  1.3048e-01, -8.0383e-02,\n",
            "         -1.5189e-01,  1.4192e-01,  2.5843e-02,  1.1620e-01,  6.3473e-02,\n",
            "         -2.4010e-01, -3.8888e-01,  3.0963e-02,  2.2403e-01, -3.1023e-02,\n",
            "         -1.7037e-01, -9.2903e-02, -1.8081e-01, -8.4558e-02, -2.4090e-02,\n",
            "          8.8482e-02, -1.0037e-01, -1.9471e-01,  8.3992e-02,  1.4089e-01,\n",
            "         -1.4961e-01, -6.8217e-03],\n",
            "        [-1.9665e-02,  9.0868e-02, -4.7393e-02, -2.2430e-02,  1.1823e-01,\n",
            "          7.5652e-02, -2.1842e-02,  9.3269e-02, -1.8144e-01, -1.2988e-01,\n",
            "          1.2316e-01, -1.9463e-01, -1.7762e-01, -1.7417e-01,  3.3947e-02,\n",
            "          1.2627e-01, -1.0822e-01, -9.4987e-02, -8.5856e-03, -1.8432e-01,\n",
            "          3.7203e-03, -1.2222e-01, -1.3903e-01, -1.4964e-01, -6.5176e-02,\n",
            "          7.1961e-02,  1.5086e-02,  9.2475e-02, -1.9122e-01, -1.5543e-01,\n",
            "          7.4665e-02,  1.2412e-01],\n",
            "        [ 1.4022e-01, -1.9176e-01,  6.0276e-02, -1.8912e-01, -7.2648e-02,\n",
            "         -2.0301e-02,  3.5888e-02, -6.8797e-02, -1.8118e-01, -3.3564e-01,\n",
            "         -8.4879e-02,  9.9444e-02,  5.1142e-02,  5.9190e-02, -1.6801e-01,\n",
            "         -1.7911e-01,  2.6974e-02,  8.3082e-02, -9.6312e-02, -7.0528e-03,\n",
            "          1.0462e-01,  1.5313e-01, -1.6639e-01, -1.0900e-01,  4.6306e-02,\n",
            "          1.2204e-01,  2.7839e-03, -3.1058e-02, -1.9231e-02,  1.4836e-01,\n",
            "         -1.7011e-01,  6.4907e-02],\n",
            "        [-1.2656e-01,  1.6808e-02, -1.6699e-01,  1.1449e-01, -9.8494e-02,\n",
            "          1.1743e-02, -1.1087e-01,  1.6189e-02, -8.6083e-02, -9.0407e-02,\n",
            "         -7.6609e-02,  1.0968e-01,  2.4704e-02, -4.5532e-02,  1.5056e-01,\n",
            "          3.4643e-02, -5.7207e-02, -7.9935e-03, -6.9118e-02, -7.0128e-02,\n",
            "         -5.5203e-02,  4.2128e-02, -1.5741e-01, -1.3767e-01,  1.1867e-01,\n",
            "         -4.2338e-02, -6.5269e-03,  6.1740e-02, -7.9071e-02,  1.2384e-01,\n",
            "         -4.0015e-02,  1.0772e-02],\n",
            "        [-1.3299e-01,  5.7284e-02, -1.3896e-01,  9.6465e-02, -3.9047e-02,\n",
            "         -8.1296e-02, -7.1149e-02,  5.5580e-02,  1.5621e-01,  4.8027e-02,\n",
            "          9.8554e-02, -1.6325e-01, -5.7054e-02, -1.1646e-01, -1.4309e-01,\n",
            "          1.5963e-02, -6.4053e-02,  2.3524e-02, -8.4218e-02, -1.7714e-01,\n",
            "         -1.0768e-01, -1.6992e-01,  2.2456e-02, -1.4976e-01,  1.2354e-01,\n",
            "          6.5438e-02, -1.1535e-01, -6.5117e-02, -1.7446e-01,  1.1674e-01,\n",
            "         -9.6066e-02, -4.9997e-02],\n",
            "        [-3.5950e-02,  4.4178e-02, -6.5363e-02,  9.9786e-02,  3.8113e-01,\n",
            "         -1.7594e-01,  1.1413e-01, -1.5561e-01, -1.3460e-01,  1.0838e-01,\n",
            "         -3.1345e-02,  4.5158e-02,  9.9420e-02, -1.5667e-01,  3.0805e-02,\n",
            "         -1.1004e-01,  2.3093e-01,  5.8394e-02,  1.6758e-01, -4.8089e-02,\n",
            "         -4.4558e-01,  6.7861e-03,  4.5879e-02,  1.2441e-02,  9.6931e-02,\n",
            "          6.1554e-02, -8.2835e-03, -8.4513e-02, -2.1547e-01, -3.8299e-02,\n",
            "          1.2445e-01,  1.3806e-01],\n",
            "        [-7.1417e-02,  1.2548e-01,  1.2813e-01, -1.6509e-01, -1.9010e-01,\n",
            "         -1.0770e-01, -3.9780e-02,  5.4150e-02,  5.3118e-02, -9.2314e-02,\n",
            "         -1.0080e-01,  9.2059e-02,  2.1092e-02, -1.4613e-01, -1.5002e-01,\n",
            "          4.5101e-02,  9.9616e-02, -1.3860e-01,  5.5761e-03, -1.8563e-01,\n",
            "          9.6997e-02,  5.2119e-02, -6.3650e-02,  7.4110e-02,  5.7747e-02,\n",
            "          1.0583e-01, -2.1517e-03, -1.4861e-02,  6.4887e-02,  4.7902e-02,\n",
            "         -1.7192e-01, -8.1361e-02],\n",
            "        [ 5.7605e-02, -1.0831e-01,  1.2367e-01, -1.9713e-02,  4.0054e-01,\n",
            "         -3.4072e-01,  1.6824e-01, -9.9847e-02,  9.7310e-02,  2.8577e-01,\n",
            "          5.8448e-02,  4.5441e-02,  1.0071e-01, -7.2879e-02, -9.1939e-02,\n",
            "         -8.8979e-02, -1.7858e-01, -2.7059e-02,  4.2756e-01, -1.6722e-01,\n",
            "         -4.2961e-01, -2.2776e-02, -2.4101e-01,  3.3102e-01, -5.6080e-02,\n",
            "         -1.6726e-01, -1.0037e-01, -2.1744e-02,  9.9182e-02, -5.7090e-02,\n",
            "          1.4896e-01, -9.0126e-02]], requires_grad=True), Parameter containing:\n",
            "tensor([-0.0504,  0.0262, -0.0503,  0.0238,  0.1898, -0.3621, -0.0516,  0.0828,\n",
            "        -0.0904,  0.1409,  0.1374, -0.1173,  0.0890, -0.2946,  0.0531, -0.1451],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([[ 0.1002,  0.3349,  0.0460, -0.1027,  0.2298, -0.3427,  0.3170, -0.1736,\n",
            "         -0.0981, -0.1940, -0.1229, -0.0713, -0.1527, -0.2074, -0.0472, -0.2299]],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([-0.0850], requires_grad=True)]\n",
            "end surrogate label_model [Parameter containing:\n",
            "tensor([[-1.2743,  1.1119,  1.3679, -1.2839, -1.7325, -1.5133,  3.4050,  1.5178,\n",
            "          1.5529, -2.5456, -1.3085,  2.6143,  1.6158,  1.3358,  3.1384, -2.9151,\n",
            "          3.7714,  1.4214, -1.8705, -1.3967,  1.0053, -1.4881,  1.5399, -1.4116,\n",
            "          1.1807,  1.3476,  1.3062,  0.9743,  1.1505,  1.3444,  2.3581, -1.6524],\n",
            "        [-1.7403,  1.3528,  1.6118, -1.5334, -1.9861, -1.8889,  4.2153,  1.8238,\n",
            "          1.8405, -3.2429, -1.5439,  3.3257,  2.0762,  1.6222,  3.6110, -4.0222,\n",
            "          4.5993,  1.7620, -2.3966, -1.8271,  0.8880, -1.5762,  2.0534, -1.6383,\n",
            "          1.7330,  1.8123,  1.7724,  1.1719,  1.4331,  1.7360,  2.7317, -1.8480],\n",
            "        [ 1.3531, -1.0170, -1.0822,  1.1786,  1.5312,  1.3411, -3.1905, -1.2436,\n",
            "         -1.2136,  2.5811,  1.1143, -2.5529, -1.5640, -1.2329, -2.8531,  3.1565,\n",
            "         -3.6107, -1.4725,  1.9185,  1.2373, -0.5564,  1.2967, -1.5428,  1.2411,\n",
            "         -1.4352, -1.2528, -1.3331, -0.9262, -1.0532, -1.3149, -2.1968,  1.3040],\n",
            "        [ 1.1807, -0.8144, -1.1130,  0.9512,  1.2750,  1.1942, -2.6774, -1.1511,\n",
            "         -1.1332,  2.0805,  0.9988, -1.9551, -1.3279, -1.1805, -2.1937,  2.6035,\n",
            "         -2.6931, -1.2428,  1.4005,  1.0281, -0.7886,  0.9819, -1.4271,  1.1060,\n",
            "         -1.0762, -1.1223, -1.1687, -0.8763, -1.0584, -1.2879, -1.6569,  1.0346],\n",
            "        [ 1.5607, -1.1058, -1.1824,  1.4361,  1.5841,  1.6843, -3.5759, -1.4841,\n",
            "         -1.6338,  2.6000,  1.4350, -2.6357, -1.4913, -1.5502, -2.9549,  2.9641,\n",
            "         -3.7258, -1.4279,  2.0018,  1.5565, -0.5934,  1.2973, -1.6906,  1.3986,\n",
            "         -1.4558, -1.5481, -1.3002, -1.1075, -1.1508, -1.4728, -2.1769,  1.4014],\n",
            "        [ 2.0786, -1.3705, -1.6703,  1.5213,  2.1695,  2.0550, -4.3555, -1.7684,\n",
            "         -1.8319,  3.2375,  1.5608, -3.2767, -1.9339, -1.8207, -3.7343,  3.9143,\n",
            "         -4.6845, -1.8721,  2.4641,  1.6339, -0.9212,  1.8598, -2.0961,  1.6909,\n",
            "         -1.7037, -1.7645, -1.6671, -1.3304, -1.5753, -1.9008, -2.8225,  1.7910],\n",
            "        [-1.5694,  1.3901,  1.5016, -1.5776, -1.9492, -1.8547,  4.1173,  1.7350,\n",
            "          1.5230, -3.2225, -1.3752,  3.1307,  1.7889,  1.4850,  3.3984, -3.6582,\n",
            "          4.2433,  1.7629, -2.0472, -1.5421,  0.6204, -1.7278,  1.9263, -1.4576,\n",
            "          1.6582,  1.6086,  1.6802,  1.0588,  1.2811,  1.8849,  2.5409, -1.7307],\n",
            "        [ 1.7621, -1.2741, -1.5667,  1.7332,  1.9391,  1.9200, -4.3921, -1.8087,\n",
            "         -1.7760,  3.4292,  1.7318, -3.1727, -2.0504, -1.9023, -3.6971,  4.0727,\n",
            "         -4.5032, -2.0294,  2.2603,  1.6990, -1.0386,  1.6321, -2.1879,  1.7955,\n",
            "         -1.7964, -1.7569, -1.7487, -1.4557, -1.5139, -1.9909, -2.7768,  1.6598]],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([ 0.7600,  1.4264, -0.3941,  0.0817, -0.5402, -1.7039,  1.2828, -1.7249],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([[ 0.2745, -0.5434, -0.5624, -0.8702, -0.4559,  0.4230,  0.0264,  0.6066]],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([2.4831], requires_grad=True)]\n",
            "original prediction score tensor([[2.0811],\n",
            "        [1.5123],\n",
            "        [1.2371],\n",
            "        [2.0557],\n",
            "        [4.7536],\n",
            "        [0.7005],\n",
            "        [2.0809],\n",
            "        [1.0452],\n",
            "        [1.6523],\n",
            "        [1.7599]], grad_fn=<AddmmBackward0>)\n",
            "surrogate prediction score  tensor([[0.9360],\n",
            "        [0.8415],\n",
            "        [0.7923],\n",
            "        [0.9269],\n",
            "        [1.3649],\n",
            "        [0.7378],\n",
            "        [0.9296],\n",
            "        [0.7619],\n",
            "        [0.8703],\n",
            "        [0.8782]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set a small regularization for the predication score\n",
        "class label_surrogate(nn.Module): # add for customerized label party\n",
        "  def __init__(self, dim_x=16, flag=False):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Linear(dim_x, 8, bias=flag),\n",
        "        nn.Linear(8, 1, bias=flag),\n",
        "        # nn.Linear(4, 1, bias=flag),\n",
        "    )\n",
        "    \n",
        "  def forward(self, x):\n",
        "    return self.layers(x)\n",
        "\n",
        "surrogate = label_surrogate(dim_x=32, flag=True)\n",
        "\n",
        "# PATH = \"/content/drive/MyDrive/epoch_m/\"+str(4)\n",
        "# mlp_new = MLP_r(dim_x=16, flag=True)\n",
        "# mlp_new.load_state_dict(torch.load(PATH), strict=False)\n",
        "\n",
        "IND = 0\n",
        "Step = 10\n",
        "num = 5\n",
        "data = dataset_train.X[IND:IND+Step]\n",
        "score = dataset_train.y[IND:IND+Step]\n",
        "\n",
        "\n",
        "known_datas = dataset_train.X[IND+Step:IND+num+Step]\n",
        "known_labels = dataset_train.y[IND+Step:IND+Step+num]\n",
        "# bias seems a strong factor no matter what we choose\n",
        "# we may need a regularization conerning the range of score we consider !\n",
        "original_label, surrogate_score, dummy_score, label_model_p = simple_short_test(mlp_new, data, score, surrogate, \n",
        "                                                                                known_datas, known_labels, \n",
        "                                                                                op=\"Adam\", iteration=3500, learning_rate=1, end_threhold=0.00001,\n",
        "                                                                                lamda1=0.1, lamda3=0.05, R_predict_flag=True, lamda2=0.001, PRINT_flg=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pOl4dsjjh9GS",
        "outputId": "93822d98-b98e-4923-9917-3c62ecd27406"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initila surrogate model parameters [Parameter containing:\n",
            "tensor([[-0.0387,  0.0357, -0.0861,  0.1038,  0.1558, -0.1297,  0.1537,  0.0331,\n",
            "          0.1306,  0.0239,  0.0852, -0.0250,  0.1363,  0.0261, -0.0825,  0.0451,\n",
            "         -0.0814, -0.0207, -0.0718,  0.1173, -0.1395, -0.0815, -0.0499, -0.1063,\n",
            "          0.0167, -0.1746,  0.1596, -0.1502,  0.1365,  0.0294, -0.0574,  0.1092],\n",
            "        [ 0.0276,  0.1428,  0.0193, -0.0558,  0.0475, -0.0479,  0.0744,  0.1578,\n",
            "          0.1022, -0.0773,  0.1020,  0.0316,  0.0898, -0.1077, -0.1750, -0.0683,\n",
            "         -0.1356,  0.1451,  0.0509,  0.0732,  0.0559, -0.0031,  0.1383, -0.1256,\n",
            "          0.0111, -0.1207,  0.0545, -0.0609,  0.0542, -0.0368,  0.1466, -0.1048],\n",
            "        [-0.1054, -0.1054,  0.1590,  0.0589,  0.1701, -0.1459, -0.1753, -0.1383,\n",
            "         -0.1189,  0.0716,  0.0633,  0.1469, -0.0913, -0.1205,  0.0938, -0.0715,\n",
            "          0.1073, -0.0419,  0.1011, -0.1373, -0.0892,  0.0539,  0.0374, -0.0451,\n",
            "          0.1054,  0.1202, -0.1282, -0.0944,  0.1619, -0.0597, -0.0627, -0.1710],\n",
            "        [-0.1012,  0.0442, -0.0233, -0.1283,  0.0041, -0.1208, -0.1500, -0.0973,\n",
            "         -0.1547, -0.1126,  0.1767,  0.0334,  0.0545, -0.1649, -0.1161, -0.0588,\n",
            "          0.0276, -0.1555, -0.0762, -0.1058,  0.0005, -0.0658, -0.0122, -0.1198,\n",
            "         -0.1213, -0.1031, -0.0605, -0.1395,  0.1482, -0.0351,  0.1521,  0.0551],\n",
            "        [-0.1497,  0.1223, -0.0486, -0.0678, -0.1467, -0.1757,  0.0506, -0.0386,\n",
            "          0.0688, -0.1451,  0.1312, -0.1298, -0.0305,  0.0369,  0.0913,  0.1427,\n",
            "          0.1610, -0.1402,  0.0445, -0.0760, -0.0194, -0.1323,  0.1610, -0.1297,\n",
            "          0.0945,  0.0621,  0.0574, -0.0956,  0.1607,  0.0388,  0.0227, -0.1558],\n",
            "        [ 0.0742, -0.0265, -0.0810,  0.1518,  0.0394, -0.0978, -0.0895, -0.0084,\n",
            "          0.0987, -0.0452, -0.1009, -0.0605, -0.1321,  0.0630,  0.1368, -0.1664,\n",
            "          0.0411,  0.0913,  0.0321, -0.0630,  0.0923,  0.0929,  0.0661, -0.0311,\n",
            "         -0.0468,  0.0189, -0.0312, -0.0527,  0.1130,  0.1519, -0.0175, -0.0396],\n",
            "        [ 0.0026, -0.0106,  0.0425,  0.0495, -0.1606, -0.0652,  0.1489,  0.0689,\n",
            "         -0.0088, -0.1066, -0.1082, -0.1584, -0.0576,  0.0597,  0.1127,  0.0816,\n",
            "         -0.1563, -0.1063, -0.0279,  0.1710,  0.0256, -0.0458,  0.0731, -0.0673,\n",
            "         -0.1144,  0.1290, -0.0804, -0.0354, -0.1759,  0.1183,  0.1339,  0.0644],\n",
            "        [-0.1233, -0.1745, -0.1436,  0.1318,  0.0849,  0.1488,  0.0926,  0.0447,\n",
            "         -0.0017, -0.1344, -0.1515, -0.1653,  0.0724, -0.0868, -0.0356, -0.1017,\n",
            "         -0.0322, -0.1244, -0.1155,  0.0586, -0.0525,  0.1091, -0.0567, -0.1297,\n",
            "         -0.0312, -0.0857, -0.0541, -0.1683,  0.0989, -0.1231,  0.0889,  0.0802]],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([ 0.1263, -0.1356,  0.1271, -0.0836,  0.0656,  0.1660, -0.0249, -0.0014],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([[-0.0814, -0.2952,  0.1697, -0.3510,  0.2195,  0.2645,  0.3344, -0.0834]],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([-0.2905], requires_grad=True)]\n",
            "0 1090941.1250\n",
            "50 149656.8438\n",
            "100 306.5182\n",
            "150 103.8637\n",
            "200 56.3782\n",
            "250 35.2308\n",
            "300 24.3253\n",
            "350 17.9881\n",
            "400 13.9570\n",
            "450 11.2220\n",
            "500 9.2766\n",
            "550 7.8405\n",
            "600 6.7463\n",
            "650 5.8884\n",
            "700 5.1977\n",
            "750 4.6271\n",
            "800 4.1443\n",
            "850 3.7263\n",
            "900 3.3569\n",
            "950 3.0244\n",
            "1000 2.7206\n",
            "1050 2.4396\n",
            "1100 2.1778\n",
            "1150 1.9330\n",
            "1200 1.7041\n",
            "1250 1.4908\n",
            "1300 1.2935\n",
            "1350 1.1127\n",
            "1400 0.9489\n",
            "1450 0.8026\n",
            "1500 0.6737\n",
            "1550 0.5620\n",
            "1600 0.4666\n",
            "1650 0.3864\n",
            "1700 0.3200\n",
            "1750 0.2659\n",
            "1800 0.2223\n",
            "1850 0.1877\n",
            "1900 0.1606\n",
            "1950 0.1396\n",
            "2000 0.1235\n",
            "2050 0.1113\n",
            "2100 0.1021\n",
            "2150 0.0953\n",
            "2200 0.0903\n",
            "2250 0.0866\n",
            "2300 0.0839\n",
            "2350 0.0819\n",
            "2400 0.0806\n",
            "2450 0.0796\n",
            "2500 0.0789\n",
            "2550 0.0784\n",
            "2600 0.0781\n",
            "2650 0.0778\n",
            "2700 0.0777\n",
            "2750 0.0776\n",
            "2800 0.0775\n",
            "2850 0.0775\n",
            "2900 0.0774\n",
            "2950 0.0774\n",
            "3000 0.0774\n",
            "3050 0.0774\n",
            "3100 0.0774\n",
            "3150 0.0774\n",
            "3200 0.0774\n",
            "3250 0.0774\n",
            "3300 0.0774\n",
            "3350 0.0774\n",
            "3400 0.0774\n",
            "3450 0.0774\n",
            "[tensor([[-5.2988e-02, -3.6751e-02, -1.7834e-01,  3.8436e-01, -1.2064e-01,\n",
            "         -7.0821e-02,  6.7794e-02,  8.1376e-04,  2.7289e-02, -8.8431e-02,\n",
            "         -1.3825e-01, -3.3690e-01,  5.2964e-02, -8.7967e-02,  1.2544e-01,\n",
            "          2.6426e-03,  1.4924e-03,  7.7748e-03,  1.1494e-02,  2.5419e-02,\n",
            "         -2.0420e-05, -1.9680e-01,  1.1638e-01, -5.6754e-02, -1.2275e-01,\n",
            "         -8.4862e-02, -1.1886e-01,  7.3101e-01, -6.8913e-02,  1.4886e-01,\n",
            "         -8.7507e-03, -1.7307e-01]])]\n",
            "GT (ground truth) original score tensor([2.5560, 1.1460, 1.3750, 1.1880, 4.2270, 0.7500, 1.2950, 1.1700, 1.4540,\n",
            "        2.2590], dtype=torch.float64)\n",
            "initial dummy score [tensor([[1.8289]]), tensor([[-0.2198]]), tensor([[0.3424]]), tensor([[-1.8048]]), tensor([[0.1166]]), tensor([[1.1357]]), tensor([[0.0063]]), tensor([[0.0756]]), tensor([[-0.1351]]), tensor([[0.3050]])]\n",
            "end dummy score [tensor([[5.1352]], requires_grad=True), tensor([[5.0714]], requires_grad=True), tensor([[3.5487]], requires_grad=True), tensor([[3.7272]], requires_grad=True), tensor([[3.8243]], requires_grad=True), tensor([[4.8318]], requires_grad=True), tensor([[5.3119]], requires_grad=True), tensor([[3.7631]], requires_grad=True), tensor([[3.5339]], requires_grad=True), tensor([[3.7878]], requires_grad=True)]\n",
            "ground truth label party model [Parameter containing:\n",
            "tensor([[ 1.0420e-01,  5.6582e-02,  1.3387e-01, -3.6587e-02,  8.4317e-02,\n",
            "          1.2280e-01, -1.3795e-01, -1.7291e-01,  6.7049e-02, -1.4631e-01,\n",
            "         -6.7284e-02, -9.2454e-02,  5.3607e-02, -1.7585e-01, -2.8838e-01,\n",
            "         -1.8006e-01, -1.3418e-02, -1.5422e-01, -4.3652e-03,  3.1625e-02,\n",
            "         -9.2438e-02,  7.9881e-02, -2.3208e-02, -8.3042e-02, -6.5755e-02,\n",
            "         -1.4054e-01,  1.4729e-01,  7.5080e-02,  1.9172e-02, -3.9980e-02,\n",
            "          9.5281e-02, -6.0263e-03],\n",
            "        [ 2.5287e-02,  4.7405e-02,  3.3741e-02,  3.0835e-01, -2.7788e-02,\n",
            "         -8.2818e-02, -1.1422e-01, -1.0720e-02, -2.0242e-02, -2.0255e-01,\n",
            "         -5.6840e-03, -2.1393e-01,  1.4305e-01, -8.8529e-02, -3.4122e-03,\n",
            "         -1.4265e-02, -5.9167e-02,  9.1029e-02,  7.8457e-02,  9.8731e-02,\n",
            "          6.4489e-02, -4.8009e-03,  2.8216e-02, -1.7204e-01, -1.7200e-01,\n",
            "          1.4888e-01, -4.7161e-02,  1.1825e-01,  1.5666e-01,  9.6406e-02,\n",
            "          1.7512e-01, -1.7664e-01],\n",
            "        [-1.7519e-01, -1.2930e-01, -1.0718e-01,  1.9719e-01, -6.4959e-02,\n",
            "         -6.3843e-02, -3.1529e-02,  2.2138e-01,  6.8027e-02, -1.3639e-01,\n",
            "         -1.5045e-01, -3.0224e-02,  1.2608e-01, -1.6597e-01, -6.6722e-02,\n",
            "         -4.4785e-02, -4.9098e-02,  1.0610e-01, -2.8738e-02,  1.0575e-02,\n",
            "         -8.8749e-02, -1.1142e-01,  9.2678e-02,  4.4228e-01, -1.6362e-01,\n",
            "         -9.3494e-02, -1.5367e-01, -8.5417e-02, -1.1704e-02,  2.1769e-01,\n",
            "          1.6295e-01,  1.0563e-01],\n",
            "        [-3.2755e-02, -7.7594e-02, -3.4985e-02, -5.1607e-02,  8.2105e-02,\n",
            "         -1.2751e-01,  3.6367e-02, -3.8997e-02,  2.8389e-02,  9.3976e-03,\n",
            "         -3.9623e-02, -8.4146e-02, -4.0868e-02,  8.5001e-02, -1.9574e-03,\n",
            "          3.0309e-02, -1.4823e-01,  3.4501e-02, -1.6336e-01,  7.3134e-02,\n",
            "          4.8965e-02, -9.8466e-03,  2.4857e-03,  1.0138e-01, -1.7971e-01,\n",
            "          2.7385e-02, -1.9790e-01, -2.5699e-02,  1.2712e-01, -7.3776e-02,\n",
            "          1.4802e-01,  1.4196e-01],\n",
            "        [ 1.3076e-01,  1.5733e-02, -3.8350e-01,  1.8004e-01,  7.5691e-03,\n",
            "         -1.0097e-01,  9.5738e-02,  5.4547e-02,  5.8216e-02, -8.5084e-02,\n",
            "          1.0553e-03, -4.1259e-01,  8.8377e-02, -2.3167e-01,  9.0818e-02,\n",
            "          9.9428e-02, -8.0342e-02, -7.8420e-02, -7.3549e-02, -4.3043e-02,\n",
            "         -7.0102e-02, -3.7839e-03,  1.4311e-01, -4.4314e-02, -1.7781e-02,\n",
            "         -1.0654e-01, -1.2270e-01,  1.0595e+00,  4.0108e-02,  1.5621e-01,\n",
            "          5.2714e-02, -2.2469e-01],\n",
            "        [-2.2831e-02,  1.2819e-01,  9.4000e-02, -8.2219e-02,  1.0913e-01,\n",
            "          1.0417e-01, -3.3307e-02,  9.3984e-02,  1.7076e-01,  2.2977e-02,\n",
            "          1.0713e-01,  3.2692e-01,  1.0759e-01, -1.2269e-01, -1.7880e-01,\n",
            "          2.3641e-01, -1.5699e-02, -3.9335e-02, -2.5490e-02,  5.5280e-02,\n",
            "          1.5577e-01,  2.8935e-01,  5.9218e-02,  2.6741e-02,  2.4264e-01,\n",
            "         -5.7505e-02,  2.3570e-01, -4.9783e-01, -1.4541e-02, -1.7118e-01,\n",
            "          1.2633e-01,  1.9211e-01],\n",
            "        [ 1.2114e-01, -1.6723e-01, -2.7666e-03,  2.5323e-02,  1.2846e-01,\n",
            "         -8.8188e-02, -7.7813e-02, -1.9374e-02, -3.2232e-02,  2.3371e-02,\n",
            "         -6.7607e-02, -4.1861e-02, -1.1664e-01,  1.5649e-01, -5.1071e-02,\n",
            "         -9.1107e-02, -1.4195e-01, -1.1159e-01,  1.0053e-01,  1.1824e-01,\n",
            "          2.6446e-02, -1.5708e-01, -1.6856e-01, -6.4272e-02, -6.0176e-02,\n",
            "         -6.7122e-02, -5.7511e-02, -9.8744e-02, -1.2348e-01,  1.2419e-02,\n",
            "         -1.4144e-01, -1.1195e-01],\n",
            "        [-2.4087e-02, -9.1598e-03,  1.3458e-01, -2.1739e-02,  9.6187e-02,\n",
            "         -3.0224e-02,  7.2520e-02, -8.2206e-02,  9.0524e-02,  8.4588e-02,\n",
            "         -1.8446e-01, -1.0866e-02, -4.2516e-02,  2.8044e-03, -1.9583e-01,\n",
            "         -1.8924e-01, -1.6009e-01, -3.2574e-02,  1.1172e-01, -1.0972e-01,\n",
            "         -7.6197e-02, -1.1299e-01,  8.0838e-02,  1.3016e-01, -4.4765e-03,\n",
            "          7.9403e-02,  1.4854e-01, -3.7541e-02, -9.3457e-02, -1.2103e-01,\n",
            "          1.1565e-01,  9.1291e-02],\n",
            "        [-1.9052e-01,  6.5445e-02,  2.2597e-01,  4.9395e-02,  4.8518e-02,\n",
            "         -3.5578e-02,  6.9209e-02, -2.2825e-01, -2.0179e-02,  7.5442e-02,\n",
            "          4.9959e-02, -3.9817e-02, -3.2793e-01,  7.7631e-02, -8.8387e-02,\n",
            "         -1.2721e-02, -1.8529e-01, -1.5286e-01,  1.5351e-01,  1.4643e-01,\n",
            "         -5.8202e-02,  1.2568e-01,  1.0434e-01, -4.7060e-02,  1.2760e-01,\n",
            "          1.1118e-01,  1.5075e-01,  1.0798e-01, -2.2381e-01, -1.3316e-01,\n",
            "         -4.2271e-02, -8.7522e-02],\n",
            "        [ 1.1181e-01,  1.4750e-01,  1.3562e-01,  3.9499e-02, -8.2579e-02,\n",
            "         -1.0726e-01, -2.0803e-02, -1.0113e-01,  1.4094e-01, -1.3561e-01,\n",
            "         -1.3794e-01, -1.0269e-01, -1.1644e-01, -1.0857e-01,  6.4792e-02,\n",
            "         -7.3235e-02, -1.1313e-01,  1.2896e-01, -7.1847e-02,  1.5813e-01,\n",
            "          1.3308e-01,  1.5149e-01, -1.5864e-01,  1.1699e-01, -1.1692e-01,\n",
            "          5.4479e-02, -1.1312e-01,  1.4976e-01,  1.6455e-01, -1.1570e-01,\n",
            "          6.5384e-02, -8.5174e-02],\n",
            "        [-6.9202e-02,  1.0737e-01,  1.2585e-01, -1.8486e-01,  3.0793e-02,\n",
            "         -1.0418e-01, -7.5093e-02,  9.1385e-02, -8.3641e-02,  1.3478e-02,\n",
            "         -1.8912e-01, -1.7940e-01, -2.2873e-01,  3.9231e-02, -1.6393e-01,\n",
            "          9.9967e-02,  4.1752e-02, -1.1931e-01,  1.6109e-01, -6.0286e-03,\n",
            "         -6.0279e-02,  6.0201e-02, -1.1238e-01, -1.1604e-01, -1.2932e-01,\n",
            "         -6.9650e-02,  7.3339e-02, -2.7869e-02, -1.6102e-01, -1.7276e-01,\n",
            "         -8.2657e-03,  5.0895e-02],\n",
            "        [-1.4895e-01,  8.5224e-02,  1.4001e-01, -2.7009e-01,  1.1604e-01,\n",
            "         -8.3061e-02, -8.2705e-02, -5.5986e-02,  6.0483e-02,  1.7813e-01,\n",
            "          1.9999e-02,  1.9879e-01,  1.2117e-01,  1.0435e-01, -2.0827e-01,\n",
            "         -5.9101e-02,  6.3983e-02,  3.9898e-01, -1.5640e-01, -1.3666e-01,\n",
            "         -4.2771e-02,  1.8031e-01,  3.0694e-02, -9.7397e-02,  1.5187e-01,\n",
            "         -9.2681e-02, -6.8561e-02, -3.5936e-01,  1.3453e-01, -3.0016e-01,\n",
            "          7.2108e-02,  1.7293e-01],\n",
            "        [-1.6074e-01,  3.7130e-02, -1.2309e-02,  3.8352e-01, -1.9056e-01,\n",
            "          1.2389e-01,  1.2190e-01,  3.6967e-02,  1.4051e-01, -1.0442e-01,\n",
            "         -8.7951e-02, -8.5824e-02,  3.6707e-03, -3.4022e-02,  1.8896e-02,\n",
            "          7.0128e-02,  3.3956e-02,  2.8150e-01,  1.5224e-01,  1.0710e-01,\n",
            "          7.7754e-02,  1.2155e-01, -1.5820e-01,  2.9166e-01, -1.2502e-01,\n",
            "         -2.5231e-01, -1.9247e-02,  2.4733e-01, -9.9520e-03,  2.2275e-01,\n",
            "          1.1902e-01, -5.2044e-02],\n",
            "        [ 1.6645e-01,  5.2031e-02,  2.6168e-01, -3.9678e-01,  9.4915e-02,\n",
            "          3.2123e-02,  1.6354e-02, -3.8812e-02,  7.8663e-02,  7.4855e-02,\n",
            "          1.9882e-01,  3.8937e-02, -1.0801e-01, -7.5998e-02, -9.1589e-02,\n",
            "          9.7821e-02, -9.6844e-02, -1.2638e-02,  4.6795e-02,  7.9345e-02,\n",
            "          8.7078e-02,  5.3318e-03,  3.9084e-03, -9.4808e-02,  2.4314e-01,\n",
            "         -3.9332e-02,  1.1662e-01, -8.8559e-01,  1.6651e-01,  2.1620e-02,\n",
            "          1.4996e-01,  1.3384e-01],\n",
            "        [ 2.7403e-01,  1.9334e-01,  1.0305e-01, -3.8388e-01,  2.7849e-01,\n",
            "         -7.2747e-02, -1.3710e-01,  1.9477e-01, -1.3948e-01,  1.5750e-01,\n",
            "          1.5326e-01,  1.1320e-01,  2.1896e-01, -1.8144e-03, -2.1300e-01,\n",
            "          5.3203e-02, -3.8247e-02, -1.4581e-02, -7.8630e-02, -1.3312e-01,\n",
            "         -1.6653e-01,  2.3759e-01, -1.3779e-01, -6.4785e-02,  1.1353e-01,\n",
            "          2.5023e-01,  1.9210e-01, -3.9070e-01,  2.0571e-01, -1.2207e-01,\n",
            "          1.6681e-02, -3.3750e-02],\n",
            "        [ 2.3850e-02,  6.7754e-02, -7.8304e-02,  3.3397e-01, -5.2145e-02,\n",
            "         -1.0113e-01,  1.0483e-01,  1.3868e-01,  4.6541e-02,  7.9935e-02,\n",
            "         -1.6267e-01, -3.9557e-01,  1.6793e-01, -1.4124e-01,  5.1704e-02,\n",
            "          1.2278e-01,  1.1907e-02, -1.5006e-02, -1.5578e-02, -4.4441e-03,\n",
            "         -2.9307e-02, -2.9837e-01,  1.5683e-01, -1.1921e-01,  3.6949e-02,\n",
            "         -1.2612e-01,  3.5168e-02,  5.5688e-01, -9.8456e-02,  1.4370e-01,\n",
            "         -4.2116e-02, -1.6216e-01]], requires_grad=True), Parameter containing:\n",
            "tensor([ 0.0951, -0.3151,  0.0497,  0.0534, -0.0915,  0.1612, -0.0358, -0.0108,\n",
            "        -0.0319, -0.0882, -0.1751, -0.1113,  0.0723, -0.0266,  0.1187, -0.0883],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([[-0.1357, -0.2421,  0.1574, -0.1076, -0.2440,  0.1339, -0.0427, -0.0730,\n",
            "         -0.3928,  0.1974, -0.0146,  0.2226,  0.3633,  0.1816,  0.2971, -0.3867]],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([0.2898], requires_grad=True)]\n",
            "end surrogate label_model [Parameter containing:\n",
            "tensor([[-1.0930, -0.9021,  0.9533, -1.4347, -0.9540, -0.9545,  0.5887, -1.1253,\n",
            "          0.5861, -0.8019, -0.7996, -0.5408, -1.0632,  0.6323,  0.7396, -0.9042,\n",
            "          0.8777, -0.8094,  0.8721,  0.5242,  0.5702, -0.9980,  0.8309,  0.6667,\n",
            "         -0.7966, -0.7943, -0.9977,  0.7071, -0.8743,  0.0364, -0.7806, -0.9738],\n",
            "        [ 0.1377,  0.1740, -0.0237,  0.3117, -0.0804,  0.0291,  0.3438,  0.2192,\n",
            "          0.1748,  0.0164,  0.0404, -0.0906,  0.0346,  0.1332, -0.0460,  0.1400,\n",
            "         -0.2356,  0.0829, -0.0350,  0.2772, -0.0489, -0.0775,  0.0405, -0.0403,\n",
            "          0.0997,  0.1575,  0.0989,  0.0197, -0.0229,  0.6485,  0.0426,  0.0962],\n",
            "        [ 0.5632,  0.4756, -0.5361,  1.4018,  0.9015,  0.2937, -0.2941,  0.6262,\n",
            "         -0.2503,  0.5377,  0.6073,  0.3492,  0.7282, -0.4063, -0.4219,  0.5043,\n",
            "         -0.4854,  0.3963, -0.4956, -0.2464, -0.4753,  0.5824, -0.4851, -0.4973,\n",
            "          0.5613,  0.3799,  0.6470, -0.6155,  0.8151,  0.2784,  0.3318,  0.5450],\n",
            "        [-0.8311, -0.6506,  0.7775, -1.7699, -0.8992, -0.8109,  0.5082, -0.8573,\n",
            "          0.4532, -0.7775, -0.6050, -0.5834, -0.8230,  0.5449,  0.6451, -0.6659,\n",
            "          0.7104, -0.8000,  0.6754,  0.5017,  0.6163, -0.8531,  0.7224,  0.5648,\n",
            "         -0.7706, -0.5944, -0.8262,  0.5929, -0.7278,  0.2069, -0.5253, -0.7226],\n",
            "        [ 0.2454,  0.2164, -0.1893,  0.2258,  0.2655, -0.0840,  0.4166,  0.3874,\n",
            "          0.3766, -0.0600,  0.2299, -0.4365,  0.4074,  0.2466,  0.1464,  0.3344,\n",
            "          0.1023, -0.2412, -0.0641,  0.3541,  0.1379,  0.0116,  0.0470,  0.0409,\n",
            "          0.2091,  0.1428,  0.3575, -0.0513,  0.5168,  1.2350, -0.1469,  0.1189],\n",
            "        [ 0.0903,  0.2020, -0.4245, -2.9033,  0.3797,  0.4815, -0.6372,  0.0497,\n",
            "         -0.5152,  0.3336,  0.2318,  0.4942,  0.0750, -0.5859, -0.4214, -0.0561,\n",
            "         -0.4273,  0.5160, -0.4032, -0.5288, -0.3437,  0.7270, -0.4205, -0.4537,\n",
            "          0.1750,  0.0778,  0.1393, -0.4849,  0.2568, -0.5345,  0.5068,  0.3510],\n",
            "        [ 0.6965,  0.6786, -0.7279,  1.5779,  0.7186,  0.6054, -0.5797,  0.7919,\n",
            "         -0.6567,  0.5429,  0.6760,  0.5076,  0.7882, -0.7023, -0.6707,  0.6605,\n",
            "         -0.8147,  0.5574, -0.7508, -0.5081, -0.5902,  0.7242, -0.6333, -0.7753,\n",
            "          0.5269,  0.6073,  0.6539, -0.7773,  0.6842, -0.4283,  0.8385,  0.7813],\n",
            "        [-0.6004, -0.3493,  0.0925, -0.0340, -0.4247, -0.0229, -0.1893, -0.4671,\n",
            "         -0.2307, -0.3039, -0.3333,  0.0647, -0.4568, -0.2168, -0.0142, -0.3678,\n",
            "          0.1141, -0.1077,  0.0817, -0.2920, -0.1275, -0.1385,  0.1430, -0.2130,\n",
            "         -0.2219, -0.2289, -0.4448, -0.1229, -0.3446, -1.2800,  0.1741, -0.2835]],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([-0.9276,  0.1477,  0.7971, -0.8086,  0.6463, -0.1425,  0.6409, -0.6540],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([[ 0.8943, -0.1642, -0.6156, -0.7431,  0.2902,  0.0874,  0.6787, -0.2994]],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([-3.8022], requires_grad=True)]\n",
            "original prediction score tensor([[2.4158],\n",
            "        [1.5756],\n",
            "        [1.2322],\n",
            "        [1.8630],\n",
            "        [4.6583],\n",
            "        [0.8432],\n",
            "        [2.1836],\n",
            "        [1.0012],\n",
            "        [1.5850],\n",
            "        [1.8270]], grad_fn=<AddmmBackward0>)\n",
            "surrogate prediction score  tensor([[-3.7130],\n",
            "        [-3.7006],\n",
            "        [-3.7134],\n",
            "        [-3.7006],\n",
            "        [-3.7105],\n",
            "        [-3.6446],\n",
            "        [-3.7046],\n",
            "        [-3.6646],\n",
            "        [-3.6831],\n",
            "        [-3.7012]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# set a small regularization for the predication score\n",
        "class label_surrogate(nn.Module): # add for customerized label party\n",
        "  def __init__(self, dim_x=16, flag=False):\n",
        "    super().__init__()\n",
        "    self.layers = nn.Sequential(\n",
        "        nn.Linear(dim_x, 8, bias=flag),\n",
        "        nn.Linear(8, 1, bias=flag),\n",
        "        # nn.Linear(4, 1, bias=flag),\n",
        "    )\n",
        "    \n",
        "  def forward(self, x):\n",
        "    return self.layers(x)\n",
        "\n",
        "surrogate = label_surrogate(dim_x=32, flag=True)\n",
        "\n",
        "# PATH = \"/content/drive/MyDrive/epoch_m/\"+str(4)\n",
        "# mlp_new = MLP_r(dim_x=16, flag=True)\n",
        "# mlp_new.load_state_dict(torch.load(PATH), strict=False)\n",
        "\n",
        "IND = 0\n",
        "Step = 10\n",
        "num = 5\n",
        "data = dataset_train.X[IND:IND+Step]\n",
        "score = dataset_train.y[IND:IND+Step]\n",
        "\n",
        "\n",
        "known_datas = dataset_train.X[IND+Step:IND+num+Step]\n",
        "known_labels = dataset_train.y[IND+Step:IND+Step+num]\n",
        "# bias seems a strong factor no matter what we choose\n",
        "# we may need a regularization conerning the range of score we consider !\n",
        "original_label, surrogate_score, dummy_score, label_model_p = simple_short_test(mlp_new, data, score, surrogate, \n",
        "                                                                                known_datas, known_labels, \n",
        "                                                                                op=\"Adam\", iteration=3500, learning_rate=1, end_threhold=0.00001,\n",
        "                                                                                lamda1=0.2, lamda3=0.05, R_predict_flag=True, lamda2=0.001, PRINT_flg=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U5I2G4SekKnf",
        "outputId": "87d4a200-5812-4246-ccd5-684aa246704b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "initila surrogate model parameters [Parameter containing:\n",
            "tensor([[ 0.1352,  0.1467, -0.0414,  0.1624, -0.0387,  0.0357, -0.0861,  0.1038,\n",
            "          0.1558, -0.1297,  0.1537,  0.0331,  0.1306,  0.0239,  0.0852, -0.0250,\n",
            "          0.1363,  0.0261, -0.0825,  0.0451, -0.0814, -0.0207, -0.0718,  0.1173,\n",
            "         -0.1395, -0.0815, -0.0499, -0.1063,  0.0167, -0.1746,  0.1596, -0.1502],\n",
            "        [ 0.1365,  0.0294, -0.0574,  0.1092,  0.0276,  0.1428,  0.0193, -0.0558,\n",
            "          0.0475, -0.0479,  0.0744,  0.1578,  0.1022, -0.0773,  0.1020,  0.0316,\n",
            "          0.0898, -0.1077, -0.1750, -0.0683, -0.1356,  0.1451,  0.0509,  0.0732,\n",
            "          0.0559, -0.0031,  0.1383, -0.1256,  0.0111, -0.1207,  0.0545, -0.0609],\n",
            "        [ 0.0542, -0.0368,  0.1466, -0.1048, -0.1054, -0.1054,  0.1590,  0.0589,\n",
            "          0.1701, -0.1459, -0.1753, -0.1383, -0.1189,  0.0716,  0.0633,  0.1469,\n",
            "         -0.0913, -0.1205,  0.0938, -0.0715,  0.1073, -0.0419,  0.1011, -0.1373,\n",
            "         -0.0892,  0.0539,  0.0374, -0.0451,  0.1054,  0.1202, -0.1282, -0.0944],\n",
            "        [ 0.1619, -0.0597, -0.0627, -0.1710, -0.1012,  0.0442, -0.0233, -0.1283,\n",
            "          0.0041, -0.1208, -0.1500, -0.0973, -0.1547, -0.1126,  0.1767,  0.0334,\n",
            "          0.0545, -0.1649, -0.1161, -0.0588,  0.0276, -0.1555, -0.0762, -0.1058,\n",
            "          0.0005, -0.0658, -0.0122, -0.1198, -0.1213, -0.1031, -0.0605, -0.1395],\n",
            "        [ 0.1482, -0.0351,  0.1521,  0.0551, -0.1497,  0.1223, -0.0486, -0.0678,\n",
            "         -0.1467, -0.1757,  0.0506, -0.0386,  0.0688, -0.1451,  0.1312, -0.1298,\n",
            "         -0.0305,  0.0369,  0.0913,  0.1427,  0.1610, -0.1402,  0.0445, -0.0760,\n",
            "         -0.0194, -0.1323,  0.1610, -0.1297,  0.0945,  0.0621,  0.0574, -0.0956],\n",
            "        [ 0.1607,  0.0388,  0.0227, -0.1558,  0.0742, -0.0265, -0.0810,  0.1518,\n",
            "          0.0394, -0.0978, -0.0895, -0.0084,  0.0987, -0.0452, -0.1009, -0.0605,\n",
            "         -0.1321,  0.0630,  0.1368, -0.1664,  0.0411,  0.0913,  0.0321, -0.0630,\n",
            "          0.0923,  0.0929,  0.0661, -0.0311, -0.0468,  0.0189, -0.0312, -0.0527],\n",
            "        [ 0.1130,  0.1519, -0.0175, -0.0396,  0.0026, -0.0106,  0.0425,  0.0495,\n",
            "         -0.1606, -0.0652,  0.1489,  0.0689, -0.0088, -0.1066, -0.1082, -0.1584,\n",
            "         -0.0576,  0.0597,  0.1127,  0.0816, -0.1563, -0.1063, -0.0279,  0.1710,\n",
            "          0.0256, -0.0458,  0.0731, -0.0673, -0.1144,  0.1290, -0.0804, -0.0354],\n",
            "        [-0.1759,  0.1183,  0.1339,  0.0644, -0.1233, -0.1745, -0.1436,  0.1318,\n",
            "          0.0849,  0.1488,  0.0926,  0.0447, -0.0017, -0.1344, -0.1515, -0.1653,\n",
            "          0.0724, -0.0868, -0.0356, -0.1017, -0.0322, -0.1244, -0.1155,  0.0586,\n",
            "         -0.0525,  0.1091, -0.0567, -0.1297, -0.0312, -0.0857, -0.0541, -0.1683]],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([ 0.0989, -0.1231,  0.0889,  0.0802,  0.1263, -0.1356,  0.1271, -0.0836],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([[ 0.1312,  0.3320, -0.0499, -0.0027, -0.0814, -0.2952,  0.1697, -0.3510]],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([0.2195], requires_grad=True)]\n",
            "L1-loss mean tensor(0.9769, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.5382, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.538197\n",
            "std       0.481579\n",
            "min       0.023677\n",
            "25%       0.246992\n",
            "50%       0.413757\n",
            "75%       0.720798\n",
            "max       1.677442\n",
            "dtype: float64\n",
            "0 66975.1172\n",
            "L1-loss mean tensor(0.7229, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.4694, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.469439\n",
            "std       0.349064\n",
            "min       0.088741\n",
            "25%       0.204414\n",
            "50%       0.354295\n",
            "75%       0.635394\n",
            "max       1.048300\n",
            "dtype: float64\n",
            "50 1729844.2500\n",
            "L1-loss mean tensor(0.5755, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.2936, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.293642\n",
            "std       0.263018\n",
            "min       0.009065\n",
            "25%       0.063093\n",
            "50%       0.265277\n",
            "75%       0.518243\n",
            "max       0.697119\n",
            "dtype: float64\n",
            "100 6364.6138\n",
            "L1-loss mean tensor(0.6336, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.3476, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.347585\n",
            "std       0.303794\n",
            "min       0.025686\n",
            "25%       0.093046\n",
            "50%       0.300846\n",
            "75%       0.537227\n",
            "max       0.814711\n",
            "dtype: float64\n",
            "150 2929.4441\n",
            "L1-loss mean tensor(0.7169, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.4227, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.422697\n",
            "std       0.311867\n",
            "min       0.051272\n",
            "25%       0.252770\n",
            "50%       0.329458\n",
            "75%       0.584698\n",
            "max       0.933488\n",
            "dtype: float64\n",
            "200 3022.9624\n",
            "L1-loss mean tensor(0.7674, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.4705, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.470530\n",
            "std       0.322296\n",
            "min       0.040019\n",
            "25%       0.322349\n",
            "50%       0.403334\n",
            "75%       0.607212\n",
            "max       1.027275\n",
            "dtype: float64\n",
            "250 2689.9258\n",
            "L1-loss mean tensor(0.7901, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.4949, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.494895\n",
            "std       0.333295\n",
            "min       0.026503\n",
            "25%       0.347817\n",
            "50%       0.465935\n",
            "75%       0.609062\n",
            "max       1.101167\n",
            "dtype: float64\n",
            "300 2341.4089\n",
            "L1-loss mean tensor(0.7949, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.5040, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.504012\n",
            "std       0.343602\n",
            "min       0.015267\n",
            "25%       0.338966\n",
            "50%       0.482653\n",
            "75%       0.634109\n",
            "max       1.161875\n",
            "dtype: float64\n",
            "350 2022.9756\n",
            "L1-loss mean tensor(0.7893, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.5041, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.504054\n",
            "std       0.354253\n",
            "min       0.005555\n",
            "25%       0.328724\n",
            "50%       0.464946\n",
            "75%       0.671253\n",
            "max       1.214508\n",
            "dtype: float64\n",
            "400 1734.7032\n",
            "L1-loss mean tensor(0.7797, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.4997, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.499721\n",
            "std       0.365335\n",
            "min       0.003110\n",
            "25%       0.318018\n",
            "50%       0.438156\n",
            "75%       0.697392\n",
            "max       1.262241\n",
            "dtype: float64\n",
            "450 1476.9309\n",
            "L1-loss mean tensor(0.7696, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.4938, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.493795\n",
            "std       0.376973\n",
            "min       0.011024\n",
            "25%       0.305642\n",
            "50%       0.410211\n",
            "75%       0.687377\n",
            "max       1.306777\n",
            "dtype: float64\n",
            "500 1248.6868\n",
            "L1-loss mean tensor(0.7583, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.4866, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.486564\n",
            "std       0.390897\n",
            "min       0.018373\n",
            "25%       0.275461\n",
            "50%       0.416468\n",
            "75%       0.649579\n",
            "max       1.348918\n",
            "dtype: float64\n",
            "550 1048.3455\n",
            "L1-loss mean tensor(0.7465, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.4788, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.478770\n",
            "std       0.406832\n",
            "min       0.025273\n",
            "25%       0.236464\n",
            "50%       0.422200\n",
            "75%       0.612216\n",
            "max       1.388985\n",
            "dtype: float64\n",
            "600 873.8293\n",
            "L1-loss mean tensor(0.7348, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.4708, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.470795\n",
            "std       0.424406\n",
            "min       0.031798\n",
            "25%       0.175465\n",
            "50%       0.427675\n",
            "75%       0.575586\n",
            "max       1.427088\n",
            "dtype: float64\n",
            "650 722.9047\n",
            "L1-loss mean tensor(0.7234, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.4628, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.462837\n",
            "std       0.443235\n",
            "min       0.019785\n",
            "25%       0.115195\n",
            "50%       0.433036\n",
            "75%       0.539880\n",
            "max       1.463254\n",
            "dtype: float64\n",
            "700 593.2678\n",
            "L1-loss mean tensor(0.7124, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.4550, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.455003\n",
            "std       0.462965\n",
            "min       0.003545\n",
            "25%       0.086241\n",
            "50%       0.438363\n",
            "75%       0.505243\n",
            "max       1.497489\n",
            "dtype: float64\n",
            "750 482.7437\n",
            "L1-loss mean tensor(0.7139, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.4628, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.462797\n",
            "std       0.466853\n",
            "min       0.007049\n",
            "25%       0.103251\n",
            "50%       0.439054\n",
            "75%       0.481018\n",
            "max       1.529803\n",
            "dtype: float64\n",
            "800 389.1802\n",
            "L1-loss mean tensor(0.7175, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.4724, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.472368\n",
            "std       0.470188\n",
            "min       0.019947\n",
            "25%       0.154778\n",
            "50%       0.420913\n",
            "75%       0.481862\n",
            "max       1.560216\n",
            "dtype: float64\n",
            "850 310.5237\n",
            "L1-loss mean tensor(0.7212, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.4818, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.481752\n",
            "std       0.474900\n",
            "min       0.032436\n",
            "25%       0.190514\n",
            "50%       0.403557\n",
            "75%       0.485228\n",
            "max       1.588754\n",
            "dtype: float64\n",
            "900 244.8688\n",
            "L1-loss mean tensor(0.7251, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.4909, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.490938\n",
            "std       0.480788\n",
            "min       0.044485\n",
            "25%       0.201023\n",
            "50%       0.387023\n",
            "75%       0.488875\n",
            "max       1.615457\n",
            "dtype: float64\n",
            "950 190.5920\n",
            "L1-loss mean tensor(0.7290, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.4999, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.499919\n",
            "std       0.487648\n",
            "min       0.056071\n",
            "25%       0.205391\n",
            "50%       0.383439\n",
            "75%       0.492813\n",
            "max       1.640363\n",
            "dtype: float64\n",
            "1000 146.0764\n",
            "L1-loss mean tensor(0.7330, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.5087, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.508688\n",
            "std       0.495286\n",
            "min       0.067186\n",
            "25%       0.191544\n",
            "50%       0.416867\n",
            "75%       0.497046\n",
            "max       1.663518\n",
            "dtype: float64\n",
            "1050 109.9627\n",
            "L1-loss mean tensor(0.7370, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.5172, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.517243\n",
            "std       0.503523\n",
            "min       0.077817\n",
            "25%       0.178460\n",
            "50%       0.420778\n",
            "75%       0.515827\n",
            "max       1.684971\n",
            "dtype: float64\n",
            "1100 81.0273\n",
            "L1-loss mean tensor(0.7411, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.5256, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.525579\n",
            "std       0.512196\n",
            "min       0.082172\n",
            "25%       0.166107\n",
            "50%       0.417722\n",
            "75%       0.537869\n",
            "max       1.704768\n",
            "dtype: float64\n",
            "1150 58.1716\n",
            "L1-loss mean tensor(0.7452, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.5337, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.533696\n",
            "std       0.521160\n",
            "min       0.085987\n",
            "25%       0.154453\n",
            "50%       0.414993\n",
            "75%       0.580725\n",
            "max       1.722965\n",
            "dtype: float64\n",
            "1200 40.4136\n",
            "L1-loss mean tensor(0.7493, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.5416, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.541593\n",
            "std       0.530293\n",
            "min       0.089605\n",
            "25%       0.143469\n",
            "50%       0.412580\n",
            "75%       0.625056\n",
            "max       1.739610\n",
            "dtype: float64\n",
            "1250 26.9307\n",
            "L1-loss mean tensor(0.7534, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.5493, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.549270\n",
            "std       0.539488\n",
            "min       0.093028\n",
            "25%       0.133123\n",
            "50%       0.410473\n",
            "75%       0.667899\n",
            "max       1.754757\n",
            "dtype: float64\n",
            "1300 16.9676\n",
            "L1-loss mean tensor(0.7575, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.5567, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.556730\n",
            "std       0.548656\n",
            "min       0.096264\n",
            "25%       0.125731\n",
            "50%       0.408656\n",
            "75%       0.709282\n",
            "max       1.768463\n",
            "dtype: float64\n",
            "1350 9.8718\n",
            "L1-loss mean tensor(0.7616, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.5640, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.563974\n",
            "std       0.557728\n",
            "min       0.099315\n",
            "25%       0.119508\n",
            "50%       0.407114\n",
            "75%       0.749244\n",
            "max       1.780785\n",
            "dtype: float64\n",
            "1400 5.1000\n",
            "L1-loss mean tensor(0.7656, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.5710, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.571004\n",
            "std       0.566645\n",
            "min       0.090950\n",
            "25%       0.117637\n",
            "50%       0.405830\n",
            "75%       0.787825\n",
            "max       1.791776\n",
            "dtype: float64\n",
            "1450 2.1717\n",
            "L1-loss mean tensor(0.7696, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.5778, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.577825\n",
            "std       0.575362\n",
            "min       0.072791\n",
            "25%       0.115836\n",
            "50%       0.404787\n",
            "75%       0.825067\n",
            "max       1.801494\n",
            "dtype: float64\n",
            "1500 0.6719\n",
            "L1-loss mean tensor(0.7736, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.5844, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.584440\n",
            "std       0.583846\n",
            "min       0.055971\n",
            "25%       0.118673\n",
            "50%       0.403966\n",
            "75%       0.861019\n",
            "max       1.809998\n",
            "dtype: float64\n",
            "1550 0.2579\n",
            "L1-loss mean tensor(0.7774, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.5909, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.590853\n",
            "std       0.592074\n",
            "min       0.040428\n",
            "25%       0.121977\n",
            "50%       0.403349\n",
            "75%       0.895731\n",
            "max       1.817347\n",
            "dtype: float64\n",
            "1600 0.6393\n",
            "L1-loss mean tensor(0.7813, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.5971, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.597072\n",
            "std       0.600032\n",
            "min       0.026102\n",
            "25%       0.125065\n",
            "50%       0.402919\n",
            "75%       0.929255\n",
            "max       1.823605\n",
            "dtype: float64\n",
            "1650 1.5744\n",
            "L1-loss mean tensor(0.7850, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.6031, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.603100\n",
            "std       0.607710\n",
            "min       0.012929\n",
            "25%       0.127948\n",
            "50%       0.402658\n",
            "75%       0.961642\n",
            "max       1.828832\n",
            "dtype: float64\n",
            "1700 2.8691\n",
            "L1-loss mean tensor(0.7887, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.6089, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.608944\n",
            "std       0.615108\n",
            "min       0.000841\n",
            "25%       0.130633\n",
            "50%       0.402548\n",
            "75%       0.992943\n",
            "max       1.833089\n",
            "dtype: float64\n",
            "1750 4.3571\n",
            "L1-loss mean tensor(0.7951, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.6167, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.616654\n",
            "std       0.619974\n",
            "min       0.010223\n",
            "25%       0.133130\n",
            "50%       0.402574\n",
            "75%       1.023210\n",
            "max       1.836435\n",
            "dtype: float64\n",
            "1800 5.9245\n",
            "L1-loss mean tensor(0.8014, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.6242, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.624168\n",
            "std       0.624588\n",
            "min       0.020328\n",
            "25%       0.135447\n",
            "50%       0.402718\n",
            "75%       1.052494\n",
            "max       1.838930\n",
            "dtype: float64\n",
            "1850 7.4637\n",
            "L1-loss mean tensor(0.8074, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.6313, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.631337\n",
            "std       0.629130\n",
            "min       0.029536\n",
            "25%       0.137594\n",
            "50%       0.402969\n",
            "75%       1.080844\n",
            "max       1.840634\n",
            "dtype: float64\n",
            "1900 8.9119\n",
            "L1-loss mean tensor(0.8131, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.6382, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.638180\n",
            "std       0.633601\n",
            "min       0.037909\n",
            "25%       0.139581\n",
            "50%       0.403311\n",
            "75%       1.108307\n",
            "max       1.841608\n",
            "dtype: float64\n",
            "1950 10.2187\n",
            "L1-loss mean tensor(0.8185, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.6447, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.644717\n",
            "std       0.638002\n",
            "min       0.045513\n",
            "25%       0.141419\n",
            "50%       0.403730\n",
            "75%       1.134932\n",
            "max       1.841911\n",
            "dtype: float64\n",
            "2000 11.3418\n",
            "L1-loss mean tensor(0.8236, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.6510, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.650964\n",
            "std       0.642334\n",
            "min       0.052399\n",
            "25%       0.143117\n",
            "50%       0.404218\n",
            "75%       1.160761\n",
            "max       1.841595\n",
            "dtype: float64\n",
            "2050 12.2680\n",
            "L1-loss mean tensor(0.8284, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.6569, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.656939\n",
            "std       0.646598\n",
            "min       0.058633\n",
            "25%       0.144686\n",
            "50%       0.404761\n",
            "75%       1.185835\n",
            "max       1.840716\n",
            "dtype: float64\n",
            "2100 12.9843\n",
            "L1-loss mean tensor(0.8330, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.6627, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.662661\n",
            "std       0.650801\n",
            "min       0.058536\n",
            "25%       0.146134\n",
            "50%       0.405353\n",
            "75%       1.210196\n",
            "max       1.839332\n",
            "dtype: float64\n",
            "2150 13.5016\n",
            "L1-loss mean tensor(0.8373, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.6681, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.668147\n",
            "std       0.654944\n",
            "min       0.055619\n",
            "25%       0.147472\n",
            "50%       0.405982\n",
            "75%       1.233882\n",
            "max       1.837493\n",
            "dtype: float64\n",
            "2200 13.8145\n",
            "L1-loss mean tensor(0.8415, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.6734, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.673411\n",
            "std       0.659032\n",
            "min       0.052768\n",
            "25%       0.148710\n",
            "50%       0.406643\n",
            "75%       1.256924\n",
            "max       1.835251\n",
            "dtype: float64\n",
            "2250 13.9546\n",
            "L1-loss mean tensor(0.8454, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.6785, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.678469\n",
            "std       0.663069\n",
            "min       0.049980\n",
            "25%       0.149857\n",
            "50%       0.407329\n",
            "75%       1.276445\n",
            "max       1.832648\n",
            "dtype: float64\n",
            "2300 13.9231\n",
            "L1-loss mean tensor(0.8492, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.6833, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.683336\n",
            "std       0.667057\n",
            "min       0.047250\n",
            "25%       0.150920\n",
            "50%       0.408032\n",
            "75%       1.286677\n",
            "max       1.829734\n",
            "dtype: float64\n",
            "2350 13.7419\n",
            "L1-loss mean tensor(0.8528, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.6880, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.688025\n",
            "std       0.671000\n",
            "min       0.044577\n",
            "25%       0.151910\n",
            "50%       0.408749\n",
            "75%       1.296705\n",
            "max       1.826554\n",
            "dtype: float64\n",
            "2400 13.4407\n",
            "L1-loss mean tensor(0.8562, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.6925, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.692548\n",
            "std       0.674899\n",
            "min       0.041957\n",
            "25%       0.152834\n",
            "50%       0.409473\n",
            "75%       1.306529\n",
            "max       1.823140\n",
            "dtype: float64\n",
            "2450 13.0265\n",
            "L1-loss mean tensor(0.8595, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.6969, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.696916\n",
            "std       0.678758\n",
            "min       0.039388\n",
            "25%       0.153699\n",
            "50%       0.410204\n",
            "75%       1.316156\n",
            "max       1.819537\n",
            "dtype: float64\n",
            "2500 12.5282\n",
            "L1-loss mean tensor(0.8626, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.7011, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.701138\n",
            "std       0.682577\n",
            "min       0.036870\n",
            "25%       0.154510\n",
            "50%       0.410934\n",
            "75%       1.325591\n",
            "max       1.815775\n",
            "dtype: float64\n",
            "2550 11.9573\n",
            "L1-loss mean tensor(0.8656, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.7052, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.705226\n",
            "std       0.686357\n",
            "min       0.034401\n",
            "25%       0.155275\n",
            "50%       0.411664\n",
            "75%       1.334834\n",
            "max       1.811890\n",
            "dtype: float64\n",
            "2600 11.3350\n",
            "L1-loss mean tensor(0.8685, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.7092, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.709187\n",
            "std       0.690099\n",
            "min       0.031980\n",
            "25%       0.156000\n",
            "50%       0.412388\n",
            "75%       1.343891\n",
            "max       1.807912\n",
            "dtype: float64\n",
            "2650 10.6832\n",
            "L1-loss mean tensor(0.8713, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.7130, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.713030\n",
            "std       0.693801\n",
            "min       0.029608\n",
            "25%       0.156692\n",
            "50%       0.413108\n",
            "75%       1.352762\n",
            "max       1.803866\n",
            "dtype: float64\n",
            "2700 9.9967\n",
            "L1-loss mean tensor(0.8740, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.7168, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.716760\n",
            "std       0.697463\n",
            "min       0.027284\n",
            "25%       0.157352\n",
            "50%       0.413820\n",
            "75%       1.361445\n",
            "max       1.799782\n",
            "dtype: float64\n",
            "2750 9.3175\n",
            "L1-loss mean tensor(0.8766, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.7204, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.720383\n",
            "std       0.701085\n",
            "min       0.025009\n",
            "25%       0.157986\n",
            "50%       0.414525\n",
            "75%       1.369943\n",
            "max       1.795683\n",
            "dtype: float64\n",
            "2800 8.6402\n",
            "L1-loss mean tensor(0.8792, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.7239, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.723906\n",
            "std       0.704663\n",
            "min       0.022783\n",
            "25%       0.158600\n",
            "50%       0.415217\n",
            "75%       1.378255\n",
            "max       1.791589\n",
            "dtype: float64\n",
            "2850 7.9618\n",
            "L1-loss mean tensor(0.8816, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.7273, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.727332\n",
            "std       0.708195\n",
            "min       0.020608\n",
            "25%       0.159196\n",
            "50%       0.415899\n",
            "75%       1.386382\n",
            "max       1.787520\n",
            "dtype: float64\n",
            "2900 7.3177\n",
            "L1-loss mean tensor(0.8840, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.7307, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.730662\n",
            "std       0.711680\n",
            "min       0.018482\n",
            "25%       0.159774\n",
            "50%       0.416569\n",
            "75%       1.394316\n",
            "max       1.783490\n",
            "dtype: float64\n",
            "2950 6.6880\n",
            "L1-loss mean tensor(0.8863, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.7339, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.733903\n",
            "std       0.715113\n",
            "min       0.016407\n",
            "25%       0.160341\n",
            "50%       0.417227\n",
            "75%       1.402059\n",
            "max       1.779517\n",
            "dtype: float64\n",
            "3000 6.0890\n",
            "L1-loss mean tensor(0.8886, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.7371, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.737056\n",
            "std       0.718492\n",
            "min       0.014386\n",
            "25%       0.160897\n",
            "50%       0.417872\n",
            "75%       1.409609\n",
            "max       1.775724\n",
            "dtype: float64\n",
            "3050 5.5270\n",
            "L1-loss mean tensor(0.8907, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.7401, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.740120\n",
            "std       0.721814\n",
            "min       0.012417\n",
            "25%       0.161440\n",
            "50%       0.418502\n",
            "75%       1.416964\n",
            "max       1.793261\n",
            "dtype: float64\n",
            "3100 4.9956\n",
            "L1-loss mean tensor(0.8929, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.7431, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.743099\n",
            "std       0.725074\n",
            "min       0.010502\n",
            "25%       0.161974\n",
            "50%       0.419118\n",
            "75%       1.424119\n",
            "max       1.810294\n",
            "dtype: float64\n",
            "3150 4.5004\n",
            "L1-loss mean tensor(0.8949, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.7460, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.745992\n",
            "std       0.728269\n",
            "min       0.008642\n",
            "25%       0.162501\n",
            "50%       0.419719\n",
            "75%       1.431070\n",
            "max       1.826819\n",
            "dtype: float64\n",
            "3200 4.0408\n",
            "L1-loss mean tensor(0.8969, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.7488, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.748800\n",
            "std       0.731397\n",
            "min       0.006836\n",
            "25%       0.163019\n",
            "50%       0.420306\n",
            "75%       1.437818\n",
            "max       1.842829\n",
            "dtype: float64\n",
            "3250 3.6171\n",
            "L1-loss mean tensor(0.8989, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.7515, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.751524\n",
            "std       0.734451\n",
            "min       0.005088\n",
            "25%       0.163531\n",
            "50%       0.420875\n",
            "75%       1.444360\n",
            "max       1.858324\n",
            "dtype: float64\n",
            "3300 3.2284\n",
            "L1-loss mean tensor(0.9008, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.7542, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.754164\n",
            "std       0.737432\n",
            "min       0.003397\n",
            "25%       0.164034\n",
            "50%       0.421431\n",
            "75%       1.450696\n",
            "max       1.873304\n",
            "dtype: float64\n",
            "3350 2.8773\n",
            "L1-loss mean tensor(0.9026, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.7567, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.756719\n",
            "std       0.740332\n",
            "min       0.001764\n",
            "25%       0.164532\n",
            "50%       0.421968\n",
            "75%       1.456815\n",
            "max       1.887766\n",
            "dtype: float64\n",
            "3400 2.5591\n",
            "L1-loss mean tensor(0.9044, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.7592, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.759189\n",
            "std       0.743151\n",
            "min       0.000189\n",
            "25%       0.165020\n",
            "50%       0.422491\n",
            "75%       1.462723\n",
            "max       1.901707\n",
            "dtype: float64\n",
            "3450 2.2643\n",
            "[tensor([[-5.2988e-02, -3.6751e-02, -1.7834e-01,  3.8436e-01, -1.2064e-01,\n",
            "         -7.0821e-02,  6.7794e-02,  8.1376e-04,  2.7289e-02, -8.8431e-02,\n",
            "         -1.3825e-01, -3.3690e-01,  5.2964e-02, -8.7967e-02,  1.2544e-01,\n",
            "          2.6426e-03,  1.4924e-03,  7.7748e-03,  1.1494e-02,  2.5419e-02,\n",
            "         -2.0420e-05, -1.9680e-01,  1.1638e-01, -5.6754e-02, -1.2275e-01,\n",
            "         -8.4862e-02, -1.1886e-01,  7.3101e-01, -6.8913e-02,  1.4886e-01,\n",
            "         -8.7507e-03, -1.7307e-01]])]\n",
            "GT (ground truth) original score tensor([2.5560, 1.1460, 1.3750, 1.1880, 4.2270, 0.7500, 1.2950, 1.1700, 1.4540,\n",
            "        2.2590], dtype=torch.float64)\n",
            "initial dummy score [tensor([[1.8289]]), tensor([[-0.2198]]), tensor([[0.3424]]), tensor([[-1.8048]]), tensor([[0.1166]]), tensor([[1.1357]]), tensor([[0.0063]]), tensor([[0.0756]]), tensor([[-0.1351]]), tensor([[0.3050]])]\n",
            "end dummy score [tensor([[1.8106]], requires_grad=True), tensor([[1.4503]], requires_grad=True), tensor([[1.5386]], requires_grad=True), tensor([[2.3218]], requires_grad=True), tensor([[4.2325]], requires_grad=True), tensor([[-0.6861]], requires_grad=True), tensor([[3.5549]], requires_grad=True), tensor([[-0.7483]], requires_grad=True), tensor([[2.2600]], requires_grad=True), tensor([[2.5575]], requires_grad=True)]\n",
            "ground truth label party model [Parameter containing:\n",
            "tensor([[ 1.0420e-01,  5.6582e-02,  1.3387e-01, -3.6587e-02,  8.4317e-02,\n",
            "          1.2280e-01, -1.3795e-01, -1.7291e-01,  6.7049e-02, -1.4631e-01,\n",
            "         -6.7284e-02, -9.2454e-02,  5.3607e-02, -1.7585e-01, -2.8838e-01,\n",
            "         -1.8006e-01, -1.3418e-02, -1.5422e-01, -4.3652e-03,  3.1625e-02,\n",
            "         -9.2438e-02,  7.9881e-02, -2.3208e-02, -8.3042e-02, -6.5755e-02,\n",
            "         -1.4054e-01,  1.4729e-01,  7.5080e-02,  1.9172e-02, -3.9980e-02,\n",
            "          9.5281e-02, -6.0263e-03],\n",
            "        [ 2.5287e-02,  4.7405e-02,  3.3741e-02,  3.0835e-01, -2.7788e-02,\n",
            "         -8.2818e-02, -1.1422e-01, -1.0720e-02, -2.0242e-02, -2.0255e-01,\n",
            "         -5.6840e-03, -2.1393e-01,  1.4305e-01, -8.8529e-02, -3.4122e-03,\n",
            "         -1.4265e-02, -5.9167e-02,  9.1029e-02,  7.8457e-02,  9.8731e-02,\n",
            "          6.4489e-02, -4.8009e-03,  2.8216e-02, -1.7204e-01, -1.7200e-01,\n",
            "          1.4888e-01, -4.7161e-02,  1.1825e-01,  1.5666e-01,  9.6406e-02,\n",
            "          1.7512e-01, -1.7664e-01],\n",
            "        [-1.7519e-01, -1.2930e-01, -1.0718e-01,  1.9719e-01, -6.4959e-02,\n",
            "         -6.3843e-02, -3.1529e-02,  2.2138e-01,  6.8027e-02, -1.3639e-01,\n",
            "         -1.5045e-01, -3.0224e-02,  1.2608e-01, -1.6597e-01, -6.6722e-02,\n",
            "         -4.4785e-02, -4.9098e-02,  1.0610e-01, -2.8738e-02,  1.0575e-02,\n",
            "         -8.8749e-02, -1.1142e-01,  9.2678e-02,  4.4228e-01, -1.6362e-01,\n",
            "         -9.3494e-02, -1.5367e-01, -8.5417e-02, -1.1704e-02,  2.1769e-01,\n",
            "          1.6295e-01,  1.0563e-01],\n",
            "        [-3.2755e-02, -7.7594e-02, -3.4985e-02, -5.1607e-02,  8.2105e-02,\n",
            "         -1.2751e-01,  3.6367e-02, -3.8997e-02,  2.8389e-02,  9.3976e-03,\n",
            "         -3.9623e-02, -8.4146e-02, -4.0868e-02,  8.5001e-02, -1.9574e-03,\n",
            "          3.0309e-02, -1.4823e-01,  3.4501e-02, -1.6336e-01,  7.3134e-02,\n",
            "          4.8965e-02, -9.8466e-03,  2.4857e-03,  1.0138e-01, -1.7971e-01,\n",
            "          2.7385e-02, -1.9790e-01, -2.5699e-02,  1.2712e-01, -7.3776e-02,\n",
            "          1.4802e-01,  1.4196e-01],\n",
            "        [ 1.3076e-01,  1.5733e-02, -3.8350e-01,  1.8004e-01,  7.5691e-03,\n",
            "         -1.0097e-01,  9.5738e-02,  5.4547e-02,  5.8216e-02, -8.5084e-02,\n",
            "          1.0553e-03, -4.1259e-01,  8.8377e-02, -2.3167e-01,  9.0818e-02,\n",
            "          9.9428e-02, -8.0342e-02, -7.8420e-02, -7.3549e-02, -4.3043e-02,\n",
            "         -7.0102e-02, -3.7839e-03,  1.4311e-01, -4.4314e-02, -1.7781e-02,\n",
            "         -1.0654e-01, -1.2270e-01,  1.0595e+00,  4.0108e-02,  1.5621e-01,\n",
            "          5.2714e-02, -2.2469e-01],\n",
            "        [-2.2831e-02,  1.2819e-01,  9.4000e-02, -8.2219e-02,  1.0913e-01,\n",
            "          1.0417e-01, -3.3307e-02,  9.3984e-02,  1.7076e-01,  2.2977e-02,\n",
            "          1.0713e-01,  3.2692e-01,  1.0759e-01, -1.2269e-01, -1.7880e-01,\n",
            "          2.3641e-01, -1.5699e-02, -3.9335e-02, -2.5490e-02,  5.5280e-02,\n",
            "          1.5577e-01,  2.8935e-01,  5.9218e-02,  2.6741e-02,  2.4264e-01,\n",
            "         -5.7505e-02,  2.3570e-01, -4.9783e-01, -1.4541e-02, -1.7118e-01,\n",
            "          1.2633e-01,  1.9211e-01],\n",
            "        [ 1.2114e-01, -1.6723e-01, -2.7666e-03,  2.5323e-02,  1.2846e-01,\n",
            "         -8.8188e-02, -7.7813e-02, -1.9374e-02, -3.2232e-02,  2.3371e-02,\n",
            "         -6.7607e-02, -4.1861e-02, -1.1664e-01,  1.5649e-01, -5.1071e-02,\n",
            "         -9.1107e-02, -1.4195e-01, -1.1159e-01,  1.0053e-01,  1.1824e-01,\n",
            "          2.6446e-02, -1.5708e-01, -1.6856e-01, -6.4272e-02, -6.0176e-02,\n",
            "         -6.7122e-02, -5.7511e-02, -9.8744e-02, -1.2348e-01,  1.2419e-02,\n",
            "         -1.4144e-01, -1.1195e-01],\n",
            "        [-2.4087e-02, -9.1598e-03,  1.3458e-01, -2.1739e-02,  9.6187e-02,\n",
            "         -3.0224e-02,  7.2520e-02, -8.2206e-02,  9.0524e-02,  8.4588e-02,\n",
            "         -1.8446e-01, -1.0866e-02, -4.2516e-02,  2.8044e-03, -1.9583e-01,\n",
            "         -1.8924e-01, -1.6009e-01, -3.2574e-02,  1.1172e-01, -1.0972e-01,\n",
            "         -7.6197e-02, -1.1299e-01,  8.0838e-02,  1.3016e-01, -4.4765e-03,\n",
            "          7.9403e-02,  1.4854e-01, -3.7541e-02, -9.3457e-02, -1.2103e-01,\n",
            "          1.1565e-01,  9.1291e-02],\n",
            "        [-1.9052e-01,  6.5445e-02,  2.2597e-01,  4.9395e-02,  4.8518e-02,\n",
            "         -3.5578e-02,  6.9209e-02, -2.2825e-01, -2.0179e-02,  7.5442e-02,\n",
            "          4.9959e-02, -3.9817e-02, -3.2793e-01,  7.7631e-02, -8.8387e-02,\n",
            "         -1.2721e-02, -1.8529e-01, -1.5286e-01,  1.5351e-01,  1.4643e-01,\n",
            "         -5.8202e-02,  1.2568e-01,  1.0434e-01, -4.7060e-02,  1.2760e-01,\n",
            "          1.1118e-01,  1.5075e-01,  1.0798e-01, -2.2381e-01, -1.3316e-01,\n",
            "         -4.2271e-02, -8.7522e-02],\n",
            "        [ 1.1181e-01,  1.4750e-01,  1.3562e-01,  3.9499e-02, -8.2579e-02,\n",
            "         -1.0726e-01, -2.0803e-02, -1.0113e-01,  1.4094e-01, -1.3561e-01,\n",
            "         -1.3794e-01, -1.0269e-01, -1.1644e-01, -1.0857e-01,  6.4792e-02,\n",
            "         -7.3235e-02, -1.1313e-01,  1.2896e-01, -7.1847e-02,  1.5813e-01,\n",
            "          1.3308e-01,  1.5149e-01, -1.5864e-01,  1.1699e-01, -1.1692e-01,\n",
            "          5.4479e-02, -1.1312e-01,  1.4976e-01,  1.6455e-01, -1.1570e-01,\n",
            "          6.5384e-02, -8.5174e-02],\n",
            "        [-6.9202e-02,  1.0737e-01,  1.2585e-01, -1.8486e-01,  3.0793e-02,\n",
            "         -1.0418e-01, -7.5093e-02,  9.1385e-02, -8.3641e-02,  1.3478e-02,\n",
            "         -1.8912e-01, -1.7940e-01, -2.2873e-01,  3.9231e-02, -1.6393e-01,\n",
            "          9.9967e-02,  4.1752e-02, -1.1931e-01,  1.6109e-01, -6.0286e-03,\n",
            "         -6.0279e-02,  6.0201e-02, -1.1238e-01, -1.1604e-01, -1.2932e-01,\n",
            "         -6.9650e-02,  7.3339e-02, -2.7869e-02, -1.6102e-01, -1.7276e-01,\n",
            "         -8.2657e-03,  5.0895e-02],\n",
            "        [-1.4895e-01,  8.5224e-02,  1.4001e-01, -2.7009e-01,  1.1604e-01,\n",
            "         -8.3061e-02, -8.2705e-02, -5.5986e-02,  6.0483e-02,  1.7813e-01,\n",
            "          1.9999e-02,  1.9879e-01,  1.2117e-01,  1.0435e-01, -2.0827e-01,\n",
            "         -5.9101e-02,  6.3983e-02,  3.9898e-01, -1.5640e-01, -1.3666e-01,\n",
            "         -4.2771e-02,  1.8031e-01,  3.0694e-02, -9.7397e-02,  1.5187e-01,\n",
            "         -9.2681e-02, -6.8561e-02, -3.5936e-01,  1.3453e-01, -3.0016e-01,\n",
            "          7.2108e-02,  1.7293e-01],\n",
            "        [-1.6074e-01,  3.7130e-02, -1.2309e-02,  3.8352e-01, -1.9056e-01,\n",
            "          1.2389e-01,  1.2190e-01,  3.6967e-02,  1.4051e-01, -1.0442e-01,\n",
            "         -8.7951e-02, -8.5824e-02,  3.6707e-03, -3.4022e-02,  1.8896e-02,\n",
            "          7.0128e-02,  3.3956e-02,  2.8150e-01,  1.5224e-01,  1.0710e-01,\n",
            "          7.7754e-02,  1.2155e-01, -1.5820e-01,  2.9166e-01, -1.2502e-01,\n",
            "         -2.5231e-01, -1.9247e-02,  2.4733e-01, -9.9520e-03,  2.2275e-01,\n",
            "          1.1902e-01, -5.2044e-02],\n",
            "        [ 1.6645e-01,  5.2031e-02,  2.6168e-01, -3.9678e-01,  9.4915e-02,\n",
            "          3.2123e-02,  1.6354e-02, -3.8812e-02,  7.8663e-02,  7.4855e-02,\n",
            "          1.9882e-01,  3.8937e-02, -1.0801e-01, -7.5998e-02, -9.1589e-02,\n",
            "          9.7821e-02, -9.6844e-02, -1.2638e-02,  4.6795e-02,  7.9345e-02,\n",
            "          8.7078e-02,  5.3318e-03,  3.9084e-03, -9.4808e-02,  2.4314e-01,\n",
            "         -3.9332e-02,  1.1662e-01, -8.8559e-01,  1.6651e-01,  2.1620e-02,\n",
            "          1.4996e-01,  1.3384e-01],\n",
            "        [ 2.7403e-01,  1.9334e-01,  1.0305e-01, -3.8388e-01,  2.7849e-01,\n",
            "         -7.2747e-02, -1.3710e-01,  1.9477e-01, -1.3948e-01,  1.5750e-01,\n",
            "          1.5326e-01,  1.1320e-01,  2.1896e-01, -1.8144e-03, -2.1300e-01,\n",
            "          5.3203e-02, -3.8247e-02, -1.4581e-02, -7.8630e-02, -1.3312e-01,\n",
            "         -1.6653e-01,  2.3759e-01, -1.3779e-01, -6.4785e-02,  1.1353e-01,\n",
            "          2.5023e-01,  1.9210e-01, -3.9070e-01,  2.0571e-01, -1.2207e-01,\n",
            "          1.6681e-02, -3.3750e-02],\n",
            "        [ 2.3850e-02,  6.7754e-02, -7.8304e-02,  3.3397e-01, -5.2145e-02,\n",
            "         -1.0113e-01,  1.0483e-01,  1.3868e-01,  4.6541e-02,  7.9935e-02,\n",
            "         -1.6267e-01, -3.9557e-01,  1.6793e-01, -1.4124e-01,  5.1704e-02,\n",
            "          1.2278e-01,  1.1907e-02, -1.5006e-02, -1.5578e-02, -4.4441e-03,\n",
            "         -2.9307e-02, -2.9837e-01,  1.5683e-01, -1.1921e-01,  3.6949e-02,\n",
            "         -1.2612e-01,  3.5168e-02,  5.5688e-01, -9.8456e-02,  1.4370e-01,\n",
            "         -4.2116e-02, -1.6216e-01]], requires_grad=True), Parameter containing:\n",
            "tensor([ 0.0951, -0.3151,  0.0497,  0.0534, -0.0915,  0.1612, -0.0358, -0.0108,\n",
            "        -0.0319, -0.0882, -0.1751, -0.1113,  0.0723, -0.0266,  0.1187, -0.0883],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([[-0.1357, -0.2421,  0.1574, -0.1076, -0.2440,  0.1339, -0.0427, -0.0730,\n",
            "         -0.3928,  0.1974, -0.0146,  0.2226,  0.3633,  0.1816,  0.2971, -0.3867]],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([0.2898], requires_grad=True)]\n",
            "end surrogate label_model [Parameter containing:\n",
            "tensor([[-0.0215, -0.8647,  3.4490, -0.3628, -0.9242, -3.2220, -3.3461, -0.8953,\n",
            "          3.4783, -1.2362, -0.2559,  2.3606, -0.1227, -3.5008, -2.9718, -0.1478,\n",
            "         -3.3425,  2.2120,  3.3461, -3.3031,  3.5108,  1.8394, -3.3590, -3.6093,\n",
            "         -0.9053, -0.9234, -0.8837, -3.6767, -0.8811, -0.3534, -3.3455, -3.6861],\n",
            "        [-1.6871, -1.7708,  1.5054, -3.1494, -1.6659, -1.5796, -1.5847, -1.3510,\n",
            "          1.6248, -1.7242, -1.6459,  1.1347, -1.7095, -1.4639, -1.6954, -1.8920,\n",
            "         -1.4736,  1.4890,  1.4370, -1.7113,  1.4083,  0.7208, -1.4926, -1.3010,\n",
            "         -1.4662, -1.6987, -1.4364, -1.4264, -1.5752, -3.3599, -1.4829, -1.4617],\n",
            "        [ 0.0464,  0.3491, -5.8387,  0.5472,  0.5670,  5.6898,  5.9440,  0.3848,\n",
            "         -5.6812,  0.5765,  0.0831, -4.8833, -0.0093,  6.1007,  5.6899,  0.0507,\n",
            "          5.9185, -4.8629, -5.8884,  5.7815, -5.9523, -4.1967,  5.9305,  6.1227,\n",
            "          0.3991,  0.4427,  0.2946,  6.0832,  0.3201,  0.4668,  5.8912,  5.9595],\n",
            "        [ 0.7211,  0.2650, -2.0813, -0.2589,  0.0216,  1.8393,  1.9842,  0.5549,\n",
            "         -1.7929,  0.0943,  0.6300, -2.0293,  0.5495,  2.1150,  1.8559,  0.7419,\n",
            "          2.0165, -1.9365, -2.1057,  1.7776, -2.0346, -1.9031,  1.9219,  1.8909,\n",
            "          0.1257,  0.1877,  0.2987,  2.0714,  0.3600, -0.4401,  1.9127,  2.0742],\n",
            "        [ 0.6690,  0.2864, -1.8167, -0.1432, -0.0081,  1.8687,  1.9011,  0.5908,\n",
            "         -1.8936,  0.0823,  0.7928, -1.9186,  0.7271,  2.0223,  1.7587,  0.5364,\n",
            "          1.8806, -1.6788, -1.8461,  1.9305, -1.8524, -1.8440,  1.9836,  1.8742,\n",
            "          0.1123,  0.1244,  0.4637,  2.0011,  0.5617, -0.3903,  1.9804,  2.0594],\n",
            "        [ 1.2975,  1.0809, -2.5282,  2.1555,  0.9051,  2.6327,  2.4807,  0.6480,\n",
            "         -2.5455,  0.9347,  0.9540, -1.4526,  1.1620,  2.3693,  2.5993,  1.1694,\n",
            "          2.4236, -1.7580, -2.4222,  2.4674, -2.4983, -0.1227,  2.5560,  2.3453,\n",
            "          0.7463,  0.9723,  0.8675,  2.3076,  0.7871,  2.2595,  2.5185,  2.3570],\n",
            "        [ 0.5122, -0.4542,  1.0816,  0.5016,  0.2287, -0.8133, -0.9450, -0.9643,\n",
            "          0.7368,  0.2873,  0.3594,  0.5661,  0.3158, -1.3864, -0.7219,  0.2309,\n",
            "         -1.0788,  0.0650,  1.0723, -0.8614,  1.0554,  0.2095, -1.0072, -1.0852,\n",
            "          0.0238, -0.2253, -0.5078, -1.3122, -0.8857,  0.9490, -1.1501, -1.2779],\n",
            "        [-1.9983, -1.4837,  0.7470, -1.1122, -2.0232, -0.6843, -0.6326, -2.0831,\n",
            "          0.6349, -0.6787, -1.9683,  1.7941, -1.9392, -0.7944, -0.5909, -1.8572,\n",
            "         -0.5739,  1.5972,  0.6282, -0.5971,  0.5876,  2.2157, -0.6702, -0.6894,\n",
            "         -2.2237, -1.7212, -1.9650, -0.9155, -1.8596, -1.3256, -0.6894, -0.8756]],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([-1.4825, -1.2235,  1.7887,  2.2905,  2.3004,  0.0940, -0.6889, -2.8832],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([[ 0.7586,  0.7825,  1.0900, -1.0313, -0.9951, -1.1862,  1.1838, -2.0477]],\n",
            "       requires_grad=True), Parameter containing:\n",
            "tensor([-1.2872], requires_grad=True)]\n",
            "original prediction score tensor([[2.4158],\n",
            "        [1.5756],\n",
            "        [1.2322],\n",
            "        [1.8630],\n",
            "        [4.6583],\n",
            "        [0.8432],\n",
            "        [2.1836],\n",
            "        [1.0012],\n",
            "        [1.5850],\n",
            "        [1.8270]], grad_fn=<AddmmBackward0>)\n",
            "surrogate prediction score  tensor([[ 1.8087],\n",
            "        [ 1.4581],\n",
            "        [ 1.5364],\n",
            "        [ 2.3341],\n",
            "        [ 4.2421],\n",
            "        [-0.6891],\n",
            "        [ 3.5691],\n",
            "        [-0.7524],\n",
            "        [ 2.2629],\n",
            "        [ 2.5509]], grad_fn=<AddmmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "oprLB9GefYLr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result_summary(score, dummy_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o-Q7ZQBri9Nr",
        "outputId": "d50f49d1-740e-4ca2-fc13-d0662bc38231"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L1-loss mean tensor(2.5921, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(2.1116, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      2.111583\n",
            "std       1.559850\n",
            "min       0.095273\n",
            "25%       1.114426\n",
            "50%       1.859144\n",
            "75%       2.880481\n",
            "max       5.442462\n",
            "dtype: float64\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(2.1116, dtype=torch.float64)"
            ]
          },
          "metadata": {},
          "execution_count": 141
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result_summary(score, dummy_score)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oL4ITUhBfZt6",
        "outputId": "6b818d67-2992-4fb4-ab84-7c720cb2c4e5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L1-loss mean tensor(0.6453, dtype=torch.float64)\n",
            "mean error rate (L1) tensor(0.4520, dtype=torch.float64)\n",
            "count    10.000000\n",
            "mean      0.452033\n",
            "std       0.391075\n",
            "min       0.092985\n",
            "25%       0.306210\n",
            "50%       0.346957\n",
            "75%       0.397328\n",
            "max       1.418489\n",
            "dtype: float64\n"
          ]
        }
      ]
    }
  ]
}